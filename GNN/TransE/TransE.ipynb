{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaaWWgjqDGht",
        "outputId": "07d5807e-201a-4248-b766-be5b7ff799ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohgGCjFABCek",
        "outputId": "1c47774e-3dac-46b7-c9a5-4b2240a75c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "from dgl.data import FB15k237Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = FB15k237Dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAhkAQI8IL5S",
        "outputId": "33e977ea-2f43-4717-9f59-2d19b0c1e6ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/FB15k-237.tgz from https://data.dgl.ai/dataset/FB15k-237.tgz...\n",
            "Extracting file to /root/.dgl/FB15k-237_40695531\n",
            "# entities: 14541\n",
            "# relations: 237\n",
            "# training edges: 272115\n",
            "# validation edges: 17535\n",
            "# testing edges: 20466\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = FB15k237Dataset()\n",
        "data = dataset[0]\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "      self.head, self.tail = data.edges()\n",
        "      self.labels = data.edata['etype']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.head)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      head = torch.tensor(self.head[idx])\n",
        "      tail = torch.tensor(self.tail[idx])\n",
        "      label = torch.tensor(self.labels[idx])\n",
        "\n",
        "      return head, label, tail\n",
        "\n",
        "dataset = CustomDataset(data)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "      dataset,\n",
        "    batch_size = 64,\n",
        "    shuffle = True,\n",
        ")"
      ],
      "metadata": {
        "id": "z7DhQNgnLehS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H3JL_BhyIMI3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data에서 head, tail, label 추출\n",
        "head, tail = data.edges()\n",
        "label = data.edata['etype']\n"
      ],
      "metadata": {
        "id": "Dfrn1GX_IPCr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn.init as init\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, k = 50, gamma = 1, dataloader = dataloader, graphs = data, epochs = 1000):\n",
        "        super(TransE, self).__init__()\n",
        "\n",
        "        self.head, self.tail = data.edges()\n",
        "        self.labels = data.edata['etype']\n",
        "        self.k = k\n",
        "        self.epochs = epochs\n",
        "        self.num_entity = len(data['entities'])\n",
        "        self.num_label = len(self.labels)\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        bound = 6 / math.sqrt(self.k)\n",
        "\n",
        "        # entity: 시작은 그냥하고 update 할 때마다 (loop 돌 때마다 normalize 해주면 됨)\n",
        "        self.entity = nn.Parameter(init.uniform_(torch.empty(self.num_entity, self.k), -bound, bound), requires_grad=True)\n",
        "        self.label = nn.Parameter(init.uniform_(torch.empty(self.num_label, self.k), -bound, bound), requires_grad=True)\n",
        "        self.label.data = F.normalize(self.embed_label.data, p=2, dim=1)\n",
        "\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # relationship matrix 만들기\n",
        "        unique_heads = torch.unique(self.head)\n",
        "        unique_tails = torch.unique(self.tail)\n",
        "        self.rel_matrix = torch.zeros((len(unique_heads), len(unique_tails)), dtype=torch.float32)\n",
        "\n",
        "        # relationship이 있는 애들 중에서 negative를 뽑는게 hard negative일 확률이 높겠지??\n",
        "        for h, l, t in zip(self.head, self.label, self.tail):\n",
        "          self.rel_matrix[h,t] = l\n",
        "\n",
        "\n",
        "    def dissimiarity(self, h, l, t):\n",
        "      # h, t: (k,) / l : (k, )\n",
        "      d = torch.sum(torch.pow(h, 2)) + torch.sum(torch.pow(l, 2)) + torch.sum(torch.pow(t, 2)) - 2 * (torch.matmul(h, t) + torch.matmul(l, t - h))\n",
        "      return d\n",
        "\n",
        "    def corrupted_tail(self, h, t):\n",
        "      related_tails = self.rel_matrix[h, :]\n",
        "      num_related_tails = related_tails.size(0)\n",
        "      if num_related_tails > 0:\n",
        "        random_index = torch.randint(num_related_tails)\n",
        "        # t일 경우 그냥 첫번째 negative sample 쓰기\n",
        "        if related_tails[random_index] == t:\n",
        "          random_index = 0\n",
        "        corrupted_tail = related_tails[random_index].item()\n",
        "      else:\n",
        "        corrupted_tail = t\n",
        "\n",
        "      return self.entity(corrupted_tail)\n",
        "\n",
        "    def corrupted_head(self, h, t):\n",
        "      related_heads = self.rel_matrix[:, t]\n",
        "      num_related_heads = related_heads.size(0)\n",
        "      if num_related_heads > 0:\n",
        "        random_index = torch.randint(num_related_heads)\n",
        "        # h일 경우 그냥 첫번째 negative sample 쓰기\n",
        "        if related_heads[random_index] == h:\n",
        "          random_index = 0\n",
        "        corrupted_head = related_heads[random_index].item()\n",
        "      else:\n",
        "        corrupted_head = h\n",
        "\n",
        "      return self.entity(corrupted_head)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        head, label, tail = batch['head'], batch['label'], batch['tail']\n",
        "\n",
        "        batch_size = head.size(0)\n",
        "        h = self.entity(head) # (batch_size, k)\n",
        "        t = self.entity(tail) # (batch_size, k)\n",
        "        l = self.label(label) # (batch_size, embed_dim)\n",
        "\n",
        "        # 행렬 연산 하면 돼서 굳이 for문 돌릴 필요 X (최대한 loop 없이 matrix 연산으로 가는게 좋음)\n",
        "        # for n in range(batch_size):\n",
        "        neg_t = self.corrupted_tail(h, t)\n",
        "        neg_h = self.corrupted_head(h, t)\n",
        "\n",
        "        pos_d = self.dissimiarity(h, l, t)\n",
        "        neg_d_h = self.dissimiarity(neg_h, l, t) # head 갈아 낀 경우\n",
        "        neg_d_t = self.dissimiarity(h, l, neg_t) # tail 갈아 낀 경우\n",
        "\n",
        "        # 원래는 random하게 tail, head 갈아끼나?? 여기선 그냥,,, 둘 다 해\n",
        "        loss1 = torch.sum(torch.sum(self.gamma + pos_d - neg_d_h))\n",
        "        loss2 = torch.sum(torch.sum(self.gamma + pos_d - neg_d_t))\n",
        "\n",
        "        loss = (loss1 + loss2) / 2\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self):\n",
        "      train_loss = []\n",
        "      optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "      for epoch in range(self.epochs):\n",
        "\n",
        "        total_loss = 0\n",
        "        for batch_data in self.dataloader:\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss = self.forward(batch_data)\n",
        "          loss.backward()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      average_loss = total_loss / len(self.dataloader)\n",
        "      print(f'Epoch {epoch + 1}/{self.epochs}, Average Loss: {average_loss:.4f}')\n",
        "      train_loss.append(average_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "gcvm8dHyI_7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyBIQMFMb9Qm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}