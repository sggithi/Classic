{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-01T17:20:05.544483Z",
          "iopub.status.busy": "2023-12-01T17:20:05.544279Z",
          "iopub.status.idle": "2023-12-01T17:20:05.547673Z",
          "shell.execute_reply": "2023-12-01T17:20:05.547122Z"
        },
        "id": "d9ELU3Pv_0Pj",
        "outputId": "75afcc84-c1b8-483d-dccf-1de40a433b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "your google drive is mounted at:  /content/drive\n",
            "Path exists\n",
            "\t /content/drive/MyDrive/DSAIL\n",
            "Path added (file under this path automatically identified)\n",
            "\t /content/drive/MyDrive/DSAIL\n"
          ]
        }
      ],
      "source": [
        "path = \"MyDrive/DSAIL\"\n",
        "def mount_drive():\n",
        "  from google.colab import drive\n",
        "  mount_location = '/content/drive'\n",
        "  drive.mount(mount_location,force_remount=True)\n",
        "  return mount_location\n",
        "import os, sys\n",
        "mount_location = mount_drive()\n",
        "print(\"your google drive is mounted at: \", mount_location)\n",
        "path = os.path.join(mount_location,path) # \"/content/drive/MyDrive/\"\n",
        "if os.path.exists(path):\n",
        "  print(\"Path exists\\n\\t\", path)\n",
        "  sys.path.append(path)\n",
        "  print(\"Path added (file under this path automatically identified)\\n\\t\", path)\n",
        "  os.chdir(path)\n",
        "else :\n",
        "  raise ValueError(\"Path does not exist. Set proper path \\n\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T17:20:05.558086Z",
          "iopub.status.busy": "2023-12-01T17:20:05.557855Z",
          "iopub.status.idle": "2023-12-01T17:20:06.322438Z",
          "shell.execute_reply": "2023-12-01T17:20:06.321900Z"
        },
        "id": "pOLo0XEtxydQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "from types import SimpleNamespace\n",
        "import torch.nn.init as init\n",
        "\n",
        "device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
        "device\n",
        "\n",
        "test = np.load(\"continous_test.npy\")\n",
        "train = np.load(\"continous_train.npy\")\n",
        "\n",
        "# implicit으로 바꾸기\n",
        "train = np.where(train > 0, 1, 0)\n",
        "test = np.where(test > 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "\n",
        "train_tensor = torch.tensor(train, dtype=torch.float32)\n",
        "test_tensor = torch.tensor(test, dtype=torch.float32)\n",
        "\n",
        "class UserItemDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rating = self.data[idx]\n",
        "        return idx, rating\n",
        "\n",
        "train_dataset = UserItemDataset(train_tensor)\n",
        "test_dataset = UserItemDataset(test_tensor)\n"
      ],
      "metadata": {
        "id": "HlKYuV421NkO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user, rating = train_dataset[0]\n",
        "print(user, rating)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP7lbzopA9Dy",
        "outputId": "041d3bd2-3133-4f65-f18e-07eec64f0b3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([1., 1., 1.,  ..., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size= 3, shuffle=True)\n",
        "i = 0\n",
        "for label, data in train_loader:\n",
        "  if i > 1:\n",
        "    break\n",
        "  i += 1\n",
        "  print(\"label\", label)\n",
        "  print(\"data\", data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwRMb0tnAldm",
        "outputId": "efdaf8dd-2a91-4681-88ff-9376ea84f99b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label tensor([ 42, 250, 652])\n",
            "data tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 0.,  ..., 0., 0., 0.]])\n",
            "label tensor([103, 664,  32])\n",
            "data tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = SimpleNamespace(\n",
        "    seed = 1,\n",
        "    batch_size = 256,\n",
        "    test_batch_size = 16,\n",
        "    lr = 1e-3,\n",
        "    num_user = train.shape[0],\n",
        "    num_item = train.shape[1],\n",
        "    epoch = 100,\n",
        "    r = 64, # hidden dimension\n",
        "    m = 0.5,\n",
        "    lambC = 10,\n",
        "    batch_size = 64,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size= config.batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size= config.batch_size, shuffle=False)\n",
        "\n",
        "print(\"train\", train_dataset.shape)\n",
        "print(\"test\", test_dataset.shape)\n",
        "print(\"train_loader_length\", len(train_loader))\n",
        "\n",
        "class CML(nn.Module):\n",
        "  def __init__(self, config, train = train, train_loader = train_loader, test_loader = test_loader):\n",
        "    super(CML, self).__init__()\n",
        "    '''\n",
        "    CML\n",
        "    user - item 관계를 당김으로써 나머지 user - user / item- item 간의 거리도 가까워짐\n",
        "\n",
        "    User / Item representation을 완성하는게 목표 (r 차원)\n",
        "\n",
        "    '''\n",
        "    self.config = config\n",
        "    self.num_user, self.num_item = config.num_user, config.num_item\n",
        "    self.r = config.r\n",
        "\n",
        "    self.w = torch.randn(self.num_user, self.num_item) # ranking weight\n",
        "    self.m = config.m # margin > 0\n",
        "    self.U = 10 # (10 ~ 20)\n",
        "\n",
        "    #########################################\n",
        "    # 원래는 item description 이용한 feature extract 부분이 포함되어야 함 (패쓰)\n",
        "    # self.f = nn.Linear(in_feature, out_feature)\n",
        "    #########################################\n",
        "\n",
        "    # Parameters\n",
        "    self.u = nn.Parameter(torch.randn(self.num_user, self.r) / self.num_user)\n",
        "    self.v = nn.Parameter(torch.randn(self.num_item, self.r) / self.num_item)\n",
        "\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr = config.lr)\n",
        "\n",
        "    self.lambC = config.lambC\n",
        "\n",
        "    self.train_loader = train_loader\n",
        "    self.test_loader = test_loader\n",
        "\n",
        "    self.positive_pairs = {}\n",
        "    # user와 positive item\n",
        "    for u in range(self.num_user):\n",
        "      self.positive_pairs[u] = []\n",
        "      for j in range(self.num_item):\n",
        "        if train[u][j] != 0\n",
        "          self.positive_pairs[u].append(j)\n",
        "\n",
        "  def d(self, i, j):\n",
        "    squared_diff = (self.u[i] - self.v[j]) ** 2\n",
        "    distance = torch.sqrt(torch.sum(squared_diff))\n",
        "\n",
        "    return distance\n",
        "\n",
        "  def distatnce_pos_neg(self, i, j, k):\n",
        "    '''\n",
        "    distance\n",
        "    (i, j): positive\n",
        "    (i, k): negative\n",
        "    m : margin\n",
        "    '''\n",
        "    distatnce_loss = torch.relu(self.m + self.d(i, j) - self.d(i, k))\n",
        "\n",
        "    return distatnce_loss\n",
        "  def update_rank(self):\n",
        "    # self.w_ij\n",
        "    for i in range(self.num_user):\n",
        "      for j in self.positive_pairs[i]:\n",
        "        d_ij = self.d(i, j)\n",
        "        negative_items = [item for item in range(self.num_item) if item not in self.positive_pairs[i]]\n",
        "        random_items = random.sample(negative_items, k= self.U)\n",
        "        k = 0 # num of impostor\n",
        "        for random in random_items:\n",
        "          if self.d(i, random) < d_ij:\n",
        "            k += 1\n",
        "        self.w[i][j] = k / self.U * self.num_item\n",
        "\n",
        "# 원래대로 라면 Lf도 있어야 함 rnlcksgek,,\n",
        "\n",
        "  def covariance_reg(self):\n",
        "    '''\n",
        "    기존의 l2 norm은 gradient 가야돼서 이렇게 하기\n",
        "    '''\n",
        "    C = None\n",
        "    return C\n",
        "\n",
        "  def forward(self, batch_user):\n",
        "    # 원래는 batch 단위로 넣으려고 했는데,,\n",
        "    loss_m = 0\n",
        "    for i in batch_user:\n",
        "      for j in self.positive_pairs[i]:\n",
        "        negative_items = [item for item in range(self.num_item) if item not in self.positive_pairs[i]]\n",
        "        for k in negative_items:\n",
        "          loss_m += self.distatnce_pos_neg(i, j, k)\n",
        "\n",
        "    loss = self.covariance_reg + loss_m * self.lambC\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def fit(self):\n",
        "    train_loss = []\n",
        "    for epoch in range(self.epochs):\n",
        "      batch_loss = 0\n",
        "      for user, ratings in self.train_loader:\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.forward(user)\n",
        "        batch_loss += (loss.item())\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        train_loss.append(loss.item())\n",
        "      print(f\"Train loss{ batch_loss / len(self.train_loader)}\")\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "z-cmULfxsZSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 미완성\n",
        "언젠가....."
      ],
      "metadata": {
        "id": "wmb60893Fmqy"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}