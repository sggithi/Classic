{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Colab setting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DSAIL')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/DSAIL')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp2VLPKnmids",
        "outputId": "fec46f36-e449-4624-aa09-e39ddf09b6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfEsegib1jW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a458838a-4718-4f04-c637-7c515e0f64e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Data U1.base로 train, u1.test로 test data만들기\n",
        "# U.data는 현재 ([\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])로 구성\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "file_path = \"ml-100k/u1.base\"\n",
        "columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
        "train_data = pd.read_csv(file_path, sep='\\t', names=columns)\n",
        "\n",
        "\n",
        "user_movie_matrix = train_data.pivot(index='user_id', columns='movie_id', values='rating')\n",
        "train = user_movie_matrix.fillna(0)\n",
        "\n",
        "file_path = \"ml-100k/u1.test\"\n",
        "columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
        "test_data = pd.read_csv(file_path, sep='\\t', names=columns)\n",
        "user_movie_matrix = test_data.pivot(index='user_id', columns='movie_id', values='rating')\n",
        "test = user_movie_matrix.fillna(0)\n",
        "\n",
        "# GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#input data가 {user, rated movie, other movie's rating, Time, Last Movie rated| one-hot- encoding으로\n",
        "# y는 score\n",
        "\n",
        "num_user_train  = train_data[\"user_id\"].max()\n",
        "num_movie_train = train_data[\"movie_id\"].max()\n",
        "num_user_test  = test_data[\"user_id\"].max()\n",
        "num_movie_test = test_data[\"movie_id\"].max()\n",
        "\n",
        "num_features_train = len(train_data)\n",
        "num_features_test = len(test_data)\n",
        "\n",
        "# Ratings\n",
        "test_R = np.load(\"continous_test.npy\")\n",
        "train_R = np.load(\"continous_train.npy\")\n",
        "\n",
        "# test_R 1591 -> 1682\n",
        "num = 1682 - 1591\n",
        "test_R = np.concatenate([test_R, np.zeros((test_R.shape[0], num))], axis=1)\n",
        "\n",
        "# normalized_ratings\n",
        "normalized_ratings_test = test_R / (test_R.sum(axis=1, keepdims=True) + 1e-13)\n",
        "normalized_ratings_train = train_R / (train_R.sum(axis = 1, keepdims=True) +1e-13)\n",
        "\n",
        "# user & movie one-hot encoding\n",
        "# user_id_onehot = pd.get_dummies(train_data['user_id'], prefix='user')\n",
        "# movie_id_onehot = pd.get_dummies(train_data['movie_id'], prefix='movie')   이러면 movie id가 연속이 아니라서 1683개의 movie가 있는데 1650 column만 생김\n",
        "\n",
        "user_train = np.zeros((num_features_train, num_user_train))\n",
        "movie_train = np.zeros((num_features_train, num_movie_train))\n",
        "other_ratings_train = np.zeros((num_features_train, num_movie_train))\n",
        "time_train = (train_data[\"timestamp\"]-874724727) / 18561911\n",
        "last_movie_train = np.zeros((num_features_train, num_movie_train))\n",
        "\n",
        "\n",
        "for i in range(num_features_train ):\n",
        "  user_train[i, train_data.iloc[i]['user_id'] - 1] = 1\n",
        "  movie_train[i, train_data.iloc[i]['movie_id'] - 1] = 1\n",
        "  other_ratings_train[i, :] = normalized_ratings_train[train_data.iloc[i]['user_id'] - 1, :]\n",
        "  if i > 0:\n",
        "    if train_data.iloc[i - 1]['user_id'] == train_data.iloc[i]['user_id']:\n",
        "      last_movie_train[i, train_data.iloc[i - 1]['movie_id'] - 1] = 1\n",
        "\n",
        "user_test = np.zeros((num_features_test, num_user_train))\n",
        "movie_test = np.zeros((num_features_test, num_movie_train))\n",
        "other_ratings_test = np.zeros((num_features_test, num_movie_train))\n",
        "time_test = (test_data[\"timestamp\"]-874724710) /18552992\n",
        "last_movie_test = np.zeros((num_features_test, num_movie_train))\n",
        "\n",
        "\n",
        "time_train = time_train.values.reshape(-1, 1)\n",
        "time_test = time_test.values.reshape(-1, 1)\n",
        "\n",
        "for i in range(num_features_test):\n",
        "  user_test[i, test_data.iloc[i]['user_id'] - 1] = 1\n",
        "  movie_test[i, test_data.iloc[i]['movie_id'] - 1] = 1\n",
        "  other_ratings_test[i, :] = normalized_ratings_test[test_data.iloc[i]['user_id'] - 1, :]\n",
        "  if i > 0:\n",
        "    if test_data.iloc[i - 1]['user_id'] == test_data.iloc[i]['user_id']:\n",
        "      last_movie_test[i, test_data.iloc[i - 1]['movie_id'] - 1] = 1\n",
        "\n",
        "\n",
        "train_features = np.concatenate([user_train, movie_train, other_ratings_train, time_train, last_movie_train], axis = 1)\n",
        "test_features = np.concatenate([user_test, movie_test, other_ratings_test, time_test, last_movie_test], axis = 1)"
      ],
      "metadata": {
        "id": "PwdQeeetBvO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"train_features.npy\", train_features)\n",
        "np.save(\"test_features.npy\", test_features)"
      ],
      "metadata": {
        "id": "mjYXFE_INpNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[\"timestamp\"].min())\n",
        "print(test_data[\"timestamp\"].min())\n",
        "print(train_data[\"timestamp\"].max())\n",
        "print(test_data[\"timestamp\"].max())\n",
        "print(893286638 - 874724727)\n",
        "print(893277702 - 874724710)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbbiun2ppXbU",
        "outputId": "65f2254c-41c2-4274-af89-426c29febb2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "874724727\n",
            "874724710\n",
            "893286638\n",
            "893277702\n",
            "18561911\n",
            "18552992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(num_movie_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaIP4YWLOKtu",
        "outputId": "b6b8d0bb-7c16-48d0-874e-9d141920b22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80000, 5990)\n",
            "(20000, 5990)\n",
            "(80000,)\n",
            "1591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_user_train, num_movie_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn5SCg1pWEvS",
        "outputId": "13cd28ed-9e8d-4105-e2a2-6fce7a0d200c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_features = np.load(\"train_features.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "y_train = train_data[\"rating\"]\n",
        "y_test = test_data[\"rating\"]"
      ],
      "metadata": {
        "id": "t4xBLBC2Jylc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_train_features = np.isnan(train_features)\n",
        "nan_test_features = np.isnan(test_features)\n",
        "nan_y_train = np.isnan(y_train)\n",
        "nan_y_test = np.isnan(y_test)\n",
        "\n",
        "# Find the maximum values\n",
        "max_train_features = np.nanmax(train_features)\n",
        "max_test_features = np.nanmax(test_features)\n",
        "max_y_train = np.nanmax(y_train)\n",
        "max_y_test = np.nanmax(y_test)\n",
        "\n",
        "print(\"NaN values:\")\n",
        "print(\"Train Features:\", np.any(nan_train_features))\n",
        "print(\"Test Features:\", np.any(nan_test_features))\n",
        "print(\"y_train:\", np.any(nan_y_train))\n",
        "print(\"y_test:\", np.any(nan_y_test))\n",
        "\n",
        "print(\"\\nMaximum values:\")\n",
        "print(\"Train Features:\", max_train_features)\n",
        "print(\"Test Features:\", max_test_features)\n",
        "print(\"y_train:\", max_y_train)\n",
        "print(\"y_test:\", max_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBlM_v7Kkvgs",
        "outputId": "49ebda6e-10c6-43bf-a607-fbbb3675c203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values:\n",
            "Train Features: False\n",
            "Test Features: False\n",
            "y_train: False\n",
            "y_test: False\n",
            "\n",
            "Maximum values:\n",
            "Train Features: 1.0\n",
            "Test Features: 1.0\n",
            "y_train: 5\n",
            "y_test: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPwS5f7O_Qna",
        "outputId": "b1049afb-3d12-46cd-9c43-187e56c36fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.init as init\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class FM(nn.Module):\n",
        "  def __init__(self, train = train_features, y_train=y_train, y_test = y_test, num_user =943, num_movie = 1682, test=test_features, k=30, learning_rate=1e-4, epochs=100, device=device):\n",
        "    '''\n",
        "    FM\n",
        "    SVM처럼 general하게 적용 가능하지만 sparse한 데이터에서도 사용될 수 있도록 고안된 모델\n",
        "    degree = 2인 경우로\n",
        "\n",
        "    self.n: # of features\n",
        "    self.k: dimension\n",
        "    '''\n",
        "    super(FM, self).__init__()\n",
        "\n",
        "    self.train_features = train # (80000, 5990)\n",
        "    self.test_features = test   # (20000, 5990)\n",
        "    self.y_train = y_train # (80000,)\n",
        "    self.y_test = y_test   # (20000,)\n",
        "\n",
        "\n",
        "    self.train_features = torch.tensor(train, dtype=torch.float32, device=device).clone().detach()\n",
        "    self.test_features = torch.tensor(test, dtype=torch.float32, device=device).clone().detach()\n",
        "    self.y_train = torch.tensor(y_train, dtype=torch.float32, device=device).clone().detach()\n",
        "    self.y_test = torch.tensor(y_test, dtype=torch.float32, device=device).clone().detach()\n",
        "\n",
        "    self.num_user = num_user\n",
        "    self.num_movie = 1682\n",
        "\n",
        "    self.n = self.train_features.shape[1]\n",
        "    self.num_features_train = self.train_features.shape[0]\n",
        "    self.num_features_test = self.test_features.shape[0]\n",
        "\n",
        "\n",
        "    # dimension\n",
        "    self.k = k\n",
        "\n",
        "    # parameter w0, wi, vi,f\n",
        "    self.w0 = nn.Parameter(init.normal_(torch.randn(1)), requires_grad=True)  # 상수 (1,)\n",
        "    self.w = nn.Parameter(init.normal_(torch.randn(self.n)), requires_grad=True)  # (n,)\n",
        "    self.V = nn.Parameter(init.normal_(torch.randn(self.n, self.k)), requires_grad=True)  # (n, k)\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.epoch = epochs\n",
        "    self.criterion = nn.MSELoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input : (1, 5990) # V : (5990, k)\n",
        "    #\n",
        "    interactions = 0.5 * (torch.sum((torch.matmul(x, self.V))).pow(2) - torch.sum(torch.matmul(x, self.V).pow(2)))\n",
        "    #print(\"interactions\", interactions.shape)\n",
        "    #print(\"x\", x, \"interactions\", interactions.item())\n",
        "    y_hat = self.w0 + torch.matmul(x, self.w) + interactions\n",
        "    #print(\"y_hat\", y_hat)\n",
        "    #print(\"y_hat\", y_hat.shape)\n",
        "    #print(\"y_hat\", y_hat)\n",
        "    return y_hat\n",
        "\n",
        "  def loss(self, train = True):\n",
        "    l2_reg = 0.01\n",
        "    reg_loss = l2_reg * (torch.norm(self.w) + torch.norm(self.V))\n",
        "    loss = reg_loss\n",
        "    if train:\n",
        "      for i in range(self.num_features_train):\n",
        "        y_hat = self.forward(self.train_features[i])\n",
        "        #print(\"y_hat\", y_hat, self.y_train[i].item())\n",
        "        loss += self.criterion(y_hat, self.y_train[i].view(-1))\n",
        "        #loss += (y_hat[0] - self.y_train[i].item()).pow(2)\n",
        "    else:\n",
        "      for i in range(self.num_features_test):\n",
        "        y_hat = self.forward(self.test_features[i])\n",
        "        loss += self.criterion(y_hat, self.y_test[i].view(-1))\n",
        "        #print(y_hat, self.y_test[i].item())\n",
        "        #loss +=  (y_hat[0] - self.y_test[i].item()).pow(2)\n",
        "\n",
        "    return loss.mean()\n",
        "\n",
        "  def fit(self):\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "    self.optimizer = torch.optim.SGD(self.parameters(), lr=self.lr)\n",
        "\n",
        "    for epoch in range(self.epoch):\n",
        "      #print(epoch)\n",
        "      train_loss = self.loss()\n",
        "      self.optimizer.zero_grad()\n",
        "      train_loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "      rmse_loss = torch.sqrt(train_loss)\n",
        "      train_loss_list.append(rmse_loss)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        test_loss = self.loss(train = False)\n",
        "        rmse_test_loss = torch.sqrt(test_loss )\n",
        "      #if epoch % 20 == 0:\n",
        "      print(f'Epoch [{epoch}/{self.epoch}], train rmse: {rmse_loss}, test_rmse: {rmse_test_loss}')\n",
        "    return train_loss_list, test_loss_list\n"
      ],
      "metadata": {
        "id": "rMWknOoG1u7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = FM(epochs = 10).to(device)\n",
        "\n",
        "# Train the model\n",
        "train_loss_list, test_loss_list = model.fit()\n",
        "\n",
        "plt.plot(train_loss_list.cpu().numpy())\n",
        "plt.plot(test_loss_list.cpu().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GUepMojN8z2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "726e442e-ddf7-46ad-bd48-d05228fd557b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/10], train rmse: 18658.57421875, test_rmse: 64215465984.0\n",
            "Epoch [1/10], train rmse: 129548918784.0, test_rmse: inf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0623e0950761>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6ece9c018722>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0;31m#print(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6ece9c018722>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;31m#print(\"y_hat\", y_hat, self.y_train[i].item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6ece9c018722>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# input : (1, 5990) # V : (5990, k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0minteractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;31m#print(\"interactions\", interactions.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#print(\"x\", x, \"interactions\", interactions.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "time stamp 그대로 넣었더니 range 이상해짐\n",
        "\n",
        "=> normalize를 했는데\n",
        "\n",
        "=> torch.empty하면 값이 너무 큰 값도 들어감 ㄷ ㄷ ㄷ ㄷ (randn로 바꿈)\n",
        "\n",
        " sequential이 아닌데 timestamp가 필요할지??\n",
        "\n",
        " +) DataLoader의 중요성...\n",
        " 메모리를 아끼려면 하나씩 학습시키는게 맞다고 생각했는데 어쨌거나 DataLoader를 통해서 batch 만큼만 메모리에 올리는게 더 효율적\n",
        "\n",
        " 위와같이 코드를 작성하면 메모리에 train data가 전부 올라가서 매우 비효율적임\n",
        "\n",
        "\n",
        "\n",
        "### GPU 이슈,, 나중에 다시 학습시켜 보기!\n",
        "\n",
        "## 흥미로운 점\n",
        "   dataset을 메모리에 전체를 올려버리면 loss.backward()를 할 때 loss가 무한대로 발산하는 경우가 생긴다.\n",
        "\n",
        "   DataLoader로 batch size만큼 올리니까 해결됨!"
      ],
      "metadata": {
        "id": "0D7_BYE3riH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "train_features = torch.tensor(np.load(\"train_features.npy\"), dtype=torch.float32, device=device)\n",
        "test_features = torch.tensor(np.load(\"test_features.npy\"), dtype=torch.float32, device=device)\n",
        "y_train = torch.tensor(train_data[\"rating\"], dtype=torch.float32, device=device)\n",
        "y_test = torch.tensor(test_data[\"rating\"], dtype=torch.float32, device=device)\n",
        "\n",
        "batch_size=64\n",
        "train_dataset = TensorDataset(train_features, y_train)\n",
        "test_dataset = TensorDataset(test_features, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xiMVv_BZ3RPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn.init as init\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class FM(nn.Module):\n",
        "  def __init__(self, train = train_features, y_train=y_train, y_test = y_test, num_user =943, num_movie = 1682, test=test_features, k=20, learning_rate=1e-4, epochs=100, device=device):\n",
        "    '''\n",
        "    FM\n",
        "    SVM처럼 general하게 적용 가능하지만 sparse한 데이터에서도 사용될 수 있도록 고안된 모델\n",
        "    degree = 2인 경우로\n",
        "\n",
        "    self.n: # of features\n",
        "    self.k: dimension\n",
        "    '''\n",
        "    super(FM, self).__init__()\n",
        "\n",
        "    self.train_features = train # (80000, 5990)\n",
        "    self.test_features = test   # (20000, 5990)\n",
        "    self.y_train = y_train # (80000,)\n",
        "    self.y_test = y_test   # (20000,)\n",
        "\n",
        "    # self.train_features = torch.tensor(train, dtype=torch.float32, device=device).clone().detach()\n",
        "    # self.test_features = torch.tensor(test, dtype=torch.float32, device=device).clone().detach()\n",
        "    # self.y_train = torch.tensor(y_train, dtype=torch.float32, device=device).clone().detach()\n",
        "    # self.y_test = torch.tensor(y_test, dtype=torch.float32, device=device).clone().detach()\n",
        "\n",
        "    self.num_user = num_user\n",
        "    self.num_movie = 1682\n",
        "\n",
        "    self.n = 5990\n",
        "    self.num_features_train = len(train)\n",
        "    self.num_features_test = len(test)\n",
        "\n",
        "\n",
        "    # dimension\n",
        "    self.k = k\n",
        "\n",
        "    # parameter w0, wi, vi,f\n",
        "    self.w0 = nn.Parameter(init.normal_(torch.randn(1)), requires_grad=True)  # 상수 (1,)\n",
        "    self.w = nn.Parameter(init.normal_(torch.randn(self.n)), requires_grad=True)  # (n,)\n",
        "    self.V = nn.Parameter(init.normal_(torch.randn(self.n, self.k)), requires_grad=True)  # (n, k)\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.epoch = epochs\n",
        "    self.criterion = nn.MSELoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input : (batch_size, 5990) # V : (5990, k)\n",
        "    #\n",
        "    interactions1 = torch.sum((torch.matmul(x, self.V))) ** 2\n",
        "    #print(\"torch.matmul\", (torch.matmul(x, self.V)))\n",
        "    #print(\"x\",x)\n",
        "    inter2 = torch.sum(torch.matmul(x, self.V)**2)\n",
        "    y_hat = self.w0 + torch.matmul(x, self.w) +  0.5 *(interactions1 - inter2)\n",
        "    #print(\"interactions\", interactions1.item(), \"intesr2\", inter2.item() ,\"y_hat\", y_hat[0])\n",
        "    return y_hat\n",
        "\n",
        "  def loss(self,x =None, y= None):\n",
        "    loss = 0\n",
        "    if train:\n",
        "      for i in range(len(x)):\n",
        "        y_hat = self.forward(x[i])\n",
        "        loss += self.criterion(y_hat, y[i].view(-1))\n",
        "\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "  def fit(self):\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "\n",
        "    self.optimizer = torch.optim.SGD(self.parameters(), lr=self.lr)\n",
        "\n",
        "    for epoch in range(self.epoch):\n",
        "      self.train()\n",
        "      print(\"epoch\", epoch)\n",
        "      for batch_x, batch_y in train_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        train_loss = self.loss( x=batch_x, y=batch_y)\n",
        "        rmse_loss = torch.sqrt(train_loss )\n",
        "        train_loss_list.append(rmse_loss)\n",
        "        self.optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "          batch_x = batch_x.to(device)\n",
        "          batch_y = batch_y.to(device)\n",
        "          test_loss = self.loss( x=batch_x, y=batch_y)\n",
        "          rmse_test_loss = torch.sqrt(test_loss )\n",
        "          test_loss_list.append(rmse_loss)\n",
        "\n",
        "      #if epoch % 20 == 0:\n",
        "      print(f'Epoch [{epoch}/{self.epoch}], train rmse: {rmse_loss}, test_rmse: {rmse_test_loss}')\n",
        "    return train_loss_list, test_loss_list\n"
      ],
      "metadata": {
        "id": "Aw6bin4OyGEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = FM(train = train_loader, test = test_loader, epochs= 10).to(device)\n",
        "\n",
        "# Train the model\n",
        "train_loss_list, test_loss_list = model.fit()\n",
        "\n",
        "plt.plot(train_loss_list.cpu().numpy())\n",
        "plt.plot(test_loss_list.cpu().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkiopR_-zXph",
        "outputId": "9501f3e4-7603-4625-a2dc-fb2ad096bdf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\n",
            "Epoch [0/10], train rmse: 109.79137420654297, test_rmse: 109.99414825439453\n",
            "epoch 1\n",
            "Epoch [1/10], train rmse: 90.23499298095703, test_rmse: 81.84952545166016\n",
            "epoch 2\n",
            "Epoch [2/10], train rmse: 65.70403289794922, test_rmse: 71.58204650878906\n",
            "epoch 3\n",
            "Epoch [3/10], train rmse: 75.85906982421875, test_rmse: 67.16705322265625\n",
            "epoch 4\n",
            "Epoch [4/10], train rmse: 69.59134674072266, test_rmse: 65.69715881347656\n",
            "epoch 5\n",
            "Epoch [5/10], train rmse: 56.22217559814453, test_rmse: 65.06596374511719\n",
            "epoch 6\n",
            "Epoch [6/10], train rmse: 76.3641128540039, test_rmse: 64.70704650878906\n",
            "epoch 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이런 식으로 CustomDataset을 만들어서 쓰는게 일반적!\n",
        "\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "# class CustomDataset(Dataset):\n",
        "#     def __init__(self):\n",
        "#       self.x_train = train_feature\n",
        "#       self.y_train = y_train\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.x_train)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#       x = torch.tensor(self.x_train[idx])\n",
        "#       y = torch.tensor(self.y_train[idx])\n",
        "\n",
        "#       return x, y\n",
        "# dataloader = Dataloader(\n",
        "#       dataset,\n",
        "#     batch_size = 64,\n",
        "#     shuffle = True,\n",
        "# )"
      ],
      "metadata": {
        "id": "hkvC0NqlRCds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a7xO3Ud71gs8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}