{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Colab setting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DSAIL')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/DSAIL')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp2VLPKnmids",
        "outputId": "07b48224-b572-43a9-888b-906f6f474116"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trust_path = 'Epinions/trust_data.txt'\n",
        "ratings_path = \"Epinions/ratings_data.txt\"\n",
        "\n",
        "trust_data = pd.read_csv(trust_path, sep='\\t')\n",
        "trust_data[['ui', 'uk', 'trust']] = trust_data.iloc[:, 0].str.split(expand=True)\n",
        "\n",
        "trust_data['ui'] = trust_data['ui'].astype(int)\n",
        "trust_data['uk'] = trust_data['uk'].astype(int)\n",
        "trust_data['trust'] = trust_data['trust'].astype(int)\n",
        "trust_data.drop(columns=trust_data.columns[0], inplace=True)\n",
        "\n",
        "subset_users = trust_data['ui'].unique()\n",
        "subset_users = np.sort(subset_users)[:100]\n",
        "trust_data_subset = trust_data[trust_data['ui'].isin(subset_users)]\n",
        "\n",
        "subset_items = trust_data_subset['uk'].unique()\n",
        "subset_items = np.sort(subset_items)[:100]\n",
        "trust_data_subset = trust_data_subset[trust_data_subset['uk'].isin(subset_items)]\n",
        "\n",
        "\n",
        "max_ui_idx = trust_data_subset['ui'].max()\n",
        "max_uk_idx = trust_data_subset['uk'].max()\n",
        "\n",
        "ui_uk_matrix = np.zeros((100, 100))\n",
        "for _, row in trust_data_subset.iterrows():\n",
        "    if(row['uk'] > 100 or row['ui'] > 100):\n",
        "      continue\n",
        "    ui_uk_matrix[row['ui']-1, row['uk']-1] = row['trust']\n",
        "\n",
        "np.save('Epinions/ui_uk_matrix.npy', ui_uk_matrix)\n",
        "#np.savetxt('Epinions/ui_uk_matrix.txt', ui_uk_matrix)\n",
        "\n",
        "rating_data = pd.read_csv(ratings_path, sep='\\t')\n",
        "rating_data[['user_id', 'item_id', 'rating']] = rating_data.iloc[:, 0].str.split(expand=True)\n",
        "\n",
        "rating_data['user_id'] = rating_data['user_id'].astype(int)\n",
        "rating_data['item_id'] = rating_data['item_id'].astype(int)\n",
        "rating_data['rating'] = rating_data['rating'].astype(int)\n",
        "rating_data.drop(columns=rating_data.columns[0], inplace=True)\n",
        "\n",
        "\n",
        "subset_users = rating_data['user_id'].unique()\n",
        "subset_users = np.sort(subset_users)[:100]\n",
        "rating_data_subset = rating_data[rating_data['user_id'].isin(subset_users)]\n",
        "\n",
        "subset_items = rating_data_subset['item_id'].unique()\n",
        "subset_items = np.sort(subset_items)[:1000]\n",
        "rating_data_subset = rating_data_subset[rating_data_subset['item_id'].isin(subset_items)]\n",
        "\n",
        "# 그냥 item 각각 100까지만 !!\n",
        "# max_user_idx = rating_data_subset['user_id'].max()\n",
        "# max_item_idx = rating_data_subset['item_id'].max()\n",
        "\n",
        "train_data, test_data = train_test_split(rating_data_subset, test_size=0.2, random_state=42)\n",
        "\n",
        "train_rating_matrix = np.zeros((100, 1000))\n",
        "test_rating_matrix = np.zeros((100, 1000))\n",
        "\n",
        "for _, row in train_data.iterrows():\n",
        "    if(row['user_id'] > 100 or row['item_id'] > 1000):\n",
        "      continue\n",
        "    train_rating_matrix[row['user_id']-1, row['item_id']-1] = row['rating']\n",
        "\n",
        "for _, row in test_data.iterrows():\n",
        "    if(row['user_id'] > 100 or row['item_id'] > 1000):\n",
        "      continue\n",
        "    test_rating_matrix[row['user_id']-1, row['item_id']-1] = row['rating']\n",
        "\n",
        "\n",
        "np.save('Epinions/train_rating_matrix.npy', train_rating_matrix)\n",
        "np.save('Epinions/test_rating_matrix.npy', test_rating_matrix)\n"
      ],
      "metadata": {
        "id": "d1dP_AJ2oc1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trust_data_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQMmQDSTOOfd",
        "outputId": "ee4efdac-88e4-44c2-e41e-30f5368181b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ui  uk  trust\n",
            "1161     7  91      1\n",
            "1166     7  60      1\n",
            "1180     7  87      1\n",
            "1199     7  23      1\n",
            "1208     7  59      1\n",
            "...     ..  ..    ...\n",
            "484285  96   1      1\n",
            "485050  21  93      1\n",
            "485056  21   1      1\n",
            "485058  21  92      1\n",
            "485059  21  59      1\n",
            "\n",
            "[569 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_rating_matrix = np.load('Epinions/train_rating_matrix.npy')\n",
        "test_rating_matrix = np.load('Epinions/test_rating_matrix.npy')\n",
        "ui_uk_matrix= np.load('Epinions/ui_uk_matrix.npy')"
      ],
      "metadata": {
        "id": "xPvagEQBKjW4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ui_uk_matrix.shape\n",
        "print(ui_uk_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo4qMHjO9iiW",
        "outputId": "943f6be9-0cc9-48e4-b2f0-64b031e6b390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 1. ... 1. 1. 1.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_rating_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRijUkG38XZk",
        "outputId": "af68275c-271c-495e-cf1f-c28a3a37f642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonzero_elements = (test_rating_matrix != 0)\n",
        "\n",
        "scaled_test_rating_matrix = (test_rating_matrix[nonzero_elements] - 1) / 4.0\n",
        "scaled_test_rating_matrix_full = np.zeros_like(test_rating_matrix)\n",
        "scaled_test_rating_matrix_full[nonzero_elements] = scaled_test_rating_matrix\n",
        "\n",
        "nonzero_elements = (train_rating_matrix != 0)\n",
        "scaled_train_rating_matrix = (train_rating_matrix[nonzero_elements] - 1) / 4.0\n",
        "scaled_train_rating_matrix_full = np.zeros_like(train_rating_matrix)\n",
        "scaled_train_rating_matrix_full[nonzero_elements] = scaled_train_rating_matrix\n"
      ],
      "metadata": {
        "id": "kjc0l0k1S3Xd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 필요한 함수들\n",
        "def g(x):\n",
        "  return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "def g_prime(x):\n",
        "  return g(x) * (1- g(x))\n",
        "\n",
        "class SOREC(nn.Module):\n",
        "  def __init__(self, train_R = scaled_train_rating_matrix_full, test_R = scaled_test_rating_matrix_full, trust = ui_uk_matrix, l=10, lambC = 10, lambdaUVZ =0.001, learning_rate=1e-3, epochs= 5):\n",
        "    '''\n",
        "    SOREC\n",
        "    논문에서는 gradient descent 직접 업데이트하는 방식\n",
        "    구현은 pytorch의 loss.backward()\n",
        "    '''\n",
        "    super(SOREC, self).__init__()\n",
        "\n",
        "    # 논문은 특이하게 m이 user 수, n이 item 수\n",
        "    self.m, self.n = train_R.shape # Rating\n",
        "    self.test_n, self.test_m = test_R.shape\n",
        "\n",
        "    self.latent_dimension = l\n",
        "\n",
        "    self.train_R = train_R # 80            (100, 1000)\n",
        "    self.test_R = test_R   # 20 비율       (100, 1000)\n",
        "    self.trust = trust     # trust ratings (100, 100)\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.epoch = epochs\n",
        "    self.lambdaC = lambC\n",
        "    self.lambdaUVZ = lambdaUVZ # 공통으로 사용\n",
        "\n",
        "    # 직접 gradient 각각 update\n",
        "    self.U = nn.Parameter(torch.randn(self.latent_dimension, self.m)) # (l, m)\n",
        "    self.Z = nn.Parameter(torch.randn(self.latent_dimension, self.m)) # (l, m)\n",
        "    self.V = nn.Parameter(torch.randn(self.latent_dimension, self.n)) # (l, n)\n",
        "\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), lr= self.lr)\n",
        "\n",
        "  def get_complete_matrix(self):\n",
        "    self.completed_rating_matrix  = torch.matmul(self.U.T, self.V)\n",
        "    return self.completed_rating_matrix\n",
        "\n",
        "  def forward_user_item(self, u):\n",
        "    # user 들어올 때마다 모든 item에 대한 rating 차이 구하기\n",
        "    predicted_rating = torch.matmul(self.U[:, u].T, self.V) # (l,) (l, n) => (n)\n",
        "    loss = 0\n",
        "    for v in range(self.n):\n",
        "      # R이 있는 경우만\n",
        "      if self.train_R[u, v]:\n",
        "        loss += (self.train_R[u, v] - g(predicted_rating[v])) ** 2\n",
        "        #print(\"u, v,\", u, v, (self.train_R[u, v] - g(predicted_rating[v])) ** 2)\n",
        "\n",
        "    return loss / 2\n",
        "\n",
        "  def forward_social(self, u):\n",
        "    # user 들어올 때마다 trusted user 대한 trust 차이 구하기\n",
        "    predicted_trust = torch.matmul(self.U[:, u].T, self.Z) # (m)\n",
        "    loss = 0\n",
        "    for z in range(self.m):\n",
        "      if self.trust[u, z]:\n",
        "        loss += (self.trust[u, z] - g(predicted_trust[z])) ** 2\n",
        "\n",
        "    return self.lambdaC * loss / 2\n",
        "\n",
        "  def test_accuracy(self):\n",
        "    completed_rating_matrix = torch.matmul(self.U.T, self.V)\n",
        "    mae_loss = 0\n",
        "    test_num = 0\n",
        "    for u in range(self.m):\n",
        "      for v in range(self.n):\n",
        "        if self.test_R[u, v]:\n",
        "          test_num += 1 # .2\n",
        "          mae_loss += abs(completed_rating_matrix[u, v] - self.test_R[u, v])\n",
        "\n",
        "    return mae_loss / test_num\n",
        "\n",
        "  def train_accuracy(self):\n",
        "    completed_rating_matrix = torch.matmul(self.U.T, self.V)\n",
        "    mae_loss = 0\n",
        "    train_num = 0\n",
        "    for u in range(self.m):\n",
        "      for v in range(self.n):\n",
        "        if self.train_R[u, v]:\n",
        "          train_num += 1 # .8\n",
        "          mae_loss += abs(completed_rating_matrix[u, v] - self.train_R[u, v])\n",
        "\n",
        "    return mae_loss / train_num\n",
        "\n",
        "\n",
        "  def fit(self):\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "\n",
        "    for epoch in range(self.epoch):\n",
        "      total_loss = 0\n",
        "      for u in range(self.m):\n",
        "\n",
        "        # user-item matrix loss\n",
        "        loss1 = self.forward_user_item(u)\n",
        "\n",
        "        # trust matrix loss\n",
        "        loss2 = self.forward_social(u)\n",
        "\n",
        "        total_loss = loss1 + loss2 + self.lambdaUVZ * (torch.sum(self.U ** 2) + torch.sum(self.V ** 2) + torch.sum(self.Z ** 2))\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "      test_mae = self.test_accuracy()\n",
        "      train_mae = self.train_accuracy()\n",
        "\n",
        "      train_loss_list.append(train_mae)\n",
        "      test_loss_list.append(test_mae)\n",
        "\n",
        "      if epoch % 40 == 0:\n",
        "\n",
        "        print(f'Epoch [{epoch}/{self.epoch}], total_loss: {total_loss}, train_mae: {train_mae}, test_mae: {test_mae}')\n",
        "\n",
        "\n",
        "    return train_loss_list, test_loss_list\n"
      ],
      "metadata": {
        "id": "rMWknOoG1u7i"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = SOREC(epochs = 200)\n",
        "\n",
        "# Train the model\n",
        "train_loss_list, test_loss_list = model.fit()\n",
        "train_loss_list = torch.tensor(train_loss_list).detach().numpy()\n",
        "test_loss_list = torch.tensor(test_loss_list).detach().numpy()\n",
        "plt.plot(train_loss_list, label='Train Loss')\n",
        "plt.plot(test_loss_list, label='Test Loss')"
      ],
      "metadata": {
        "id": "xFRbHX6d2cT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "a8b12d72-fad5-4a49-96c3-381da3f609bd"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/200], total_loss: 11.483431816101074, train_mae: 2.22940731048584, test_mae: 2.4190123081207275\n",
            "Epoch [40/200], total_loss: 1.762978434562683, train_mae: 0.37445834279060364, test_mae: 0.838713526725769\n",
            "Epoch [80/200], total_loss: 1.2129321098327637, train_mae: 0.2844747304916382, test_mae: 0.7525971531867981\n",
            "Epoch [120/200], total_loss: 0.8773898482322693, train_mae: 0.3227185010910034, test_mae: 0.7190210223197937\n",
            "Epoch [160/200], total_loss: 0.7156668901443481, train_mae: 0.34875792264938354, test_mae: 0.710475742816925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f89322bd7e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGeCAYAAABGlgGHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBsUlEQVR4nO3deXxb1Z3///fVYnm343iPnR2ykIUQIIS9JU3Il1KglKGUToBhKTS0pbQdvulvCi0zX8KUocy0Q1laIJ1SCqVsw1IgJE3SNBvZgJDE2eMsXrJ5tyVLur8/riRbiR3biaxrW6/n43Efko7ulT63l1jvnnvuuYZpmqYAAABs4rC7AAAAkNgIIwAAwFaEEQAAYCvCCAAAsBVhBAAA2IowAgAAbEUYAQAAtiKMAAAAWxFGAACArVx2F9AdwWBQBw8eVEZGhgzDsLscAADQDaZpqr6+XsXFxXI4TtL/YfbAI488Yp577rlmenq6mZeXZ15zzTXm1q1bT7rNCy+8YEqKWjweT0++1ty3b98Jn8HCwsLCwsLSP5Z9+/ad9He+Rz0jS5cu1dy5c3XeeefJ7/frxz/+sWbOnKnNmzcrLS2t0+0yMzNVVlYWed3T3o2MjAxJ0r59+5SZmdmjbQEAgD3q6upUWloa+R3vTI/CyPvvvx/1esGCBcrPz9e6det06aWXdrqdYRgqLCzsyVedsL1khRrCCAAA/UtXnRCnNYC1trZWkpSTk3PS9RoaGjRs2DCVlpbqmmuu0eeff37S9b1er+rq6qIWAAAwMJ1yGAkGg7rvvvt00UUXacKECZ2uN2bMGD3//PN666239OKLLyoYDOrCCy/U/v37O91m/vz5ysrKiiylpaWnWiYAAOjjDNM0zVPZ8J577tFf/vIXLV++XCUlJd3errW1VePGjdNNN92kf/3Xf+1wHa/XK6/XG3kdPudUW1vLaRoAAPqJuro6ZWVldfn7fUqX9t5777165513tGzZsh4FEUlyu92aMmWKduzY0ek6Ho9HHo/nVEoDAAD9TI9O05imqXvvvVdvvPGGFi9erBEjRvT4CwOBgD777DMVFRX1eFsAADDw9KhnZO7cuXrppZf01ltvKSMjQ5WVlZKkrKwspaSkSJLmzJmjIUOGaP78+ZKkhx9+WBdccIFGjx6tmpoaPfbYY9q7d6/uuOOOGO8KAADoj3oURp566ilJ0uWXXx7V/sILL+jWW2+VJJWXl0fNsnbs2DHdeeedqqys1KBBgzR16lStWLFC48ePP73KAQDAgHDKA1jjqbsDYAAAQN/R3d9vbpQHAABsRRgBAAC2IowAAABbEUYAAICtEjuMrHpaeuf70qFtdlcCAEDCSuwwsunP0trnpcOEEQAA7JLYYSQ113psOmxvHQAAJLDEDiNpg63HRsIIAAB2SewwEu4ZIYwAAGCbxA4jaZymAQDAbokdRugZAQDAdokdRtLyrEd6RgAAsE2Ch5HwANYj9tYBAEACS+ww0v7S3r5/82IAAAakxA4j4QGsAZ/krbO3FgAAElRihxF3iuROs54ziBUAAFskdhiR2saNNDFuBAAAOxBGuLwXAABbEUa4vBcAAFsRRtLoGQEAwE6EkVRulgcAgJ0II9yfBgAAWxFGGMAKAICtCCP0jAAAYCvCSGQAK/OMAABgB8II96cBAMBWhJFwz4i/RfI12FsLAAAJiDCSlCa5UqznDGIFACDuCCNSu0GsjBsBACDeCCMSE58BAGAjwojE5b0AANiIMCK13SyPnhEAAOKOMCK1O01zyN46AABIQIQRSUrPtx4JIwAAxJ3L7gLs9KNXP9HGfTX67dkZGiZJDVV2lwQAQMJJ6J6RvUebtL26QQcDGVZDQ7W9BQEAkIASOowUZyVLksp9mVZDfaWN1QAAkJgSOowUZVszr+5pSbMamo9Kfp+NFQEAkHgSOowUh8LIzoYkyREaPsMgVgAA4iqxw0joNM2BWq+UXmA1MogVAIC4SuwwEuoZqahtabu8lzACAEBcJXYYybLCyNFGnwKphBEAAOyQ0GEkM8WltCSnJKkxKTQLK5f3AgAQVwkdRgzDiFxRU+PIsRq5vBcAgLhK6DAitY0bOaRsq4HTNAAAxBVhJHRFTYU/NPEZp2kAAIirhA8jRaFBrHt94SnhOU0DAEA8JXwYKc62ekZ2NqdaDQ3VkmnaWBEAAImFMBIaM7Kl3nqUv0Xy1tlYEQAAiYUwEgoje+tMmZ7wDfMYxAoAQLwkfBgpCg1gbfIFFExj4jMAAOIt4cNIstupwWlJkqQWT67VSBgBACBuEj6MSFJRaBBrgys08RlhBACAuCGMqN09ahyEEQAA4o0worZBrFXBLKuBic8AAIgbwojaBrHu94cmPuP+NAAAxA1hRG09I3tawrOwcpoGAIB4IYyobRbWbU1pVkN9hY3VAACQWAgjausZ+bw+FEaaj0mtLTZWBABA4iCMSMrPSJbTYehIMFWm0+oloXcEAID4IIxIcjoMFWYmSzLkTS2wGgkjAADEBWEkJHxFTWNSntVQd9DGagAASByEkZDwuJFjzsFWA5f3AgAQF4SRkPCU8NVGaBZWTtMAABAXhJGQ8JTwB/zZVgOnaQAAiAvCSEj4NM0uX2hKeHpGAACIC8JISHgA67amdKuBMAIAQFwQRkKGhHpGysJhpK5CMk0bKwIAIDH0KIzMnz9f5513njIyMpSfn69rr71WZWVlXW736quvauzYsUpOTtbEiRP13nvvnXLBvSU71a1kt0PV5iCrIeC1ZmIFAAC9qkdhZOnSpZo7d65WrVqlhQsXqrW1VTNnzlRjY2On26xYsUI33XSTbr/9dm3YsEHXXnutrr32Wm3atOm0i48lwzBUnJ0in9xq9YSuqGEQKwAAvc4wzVM/F3Ho0CHl5+dr6dKluvTSSztc58Ybb1RjY6PeeeedSNsFF1ygs88+W08//XSH23i9Xnm93sjruro6lZaWqra2VpmZmadabpe++dvVWr7jsDbm/1TZddukm1+TzpjRa98HAMBAVldXp6ysrC5/v09rzEhtba0kKScnp9N1Vq5cqRkzon/QZ82apZUrV3a6zfz585WVlRVZSktLT6fMbgvfvbfGmWs11NMzAgBAbzvlMBIMBnXffffpoosu0oQJEzpdr7KyUgUFBVFtBQUFqqzsfIbTefPmqba2NrLs27fvVMvskaLQXCPVRmgW1jquqAEAoLe5TnXDuXPnatOmTVq+fHks65EkeTweeTyemH9uV8I9IwcD2VYDPSMAAPS6Uwoj9957r9555x0tW7ZMJSUlJ123sLBQVVVVUW1VVVUqLCw8la/uVeGJz3b7Que16BkBAKDX9eg0jWmauvfee/XGG29o8eLFGjFiRJfbTJ8+XYsWLYpqW7hwoaZPn96zSuMgPNfItkYmPgMAIF561DMyd+5cvfTSS3rrrbeUkZERGfeRlZWllBTrh3zOnDkaMmSI5s+fL0n63ve+p8suu0yPP/64rrrqKr388stau3atnn322RjvyukL94zsbc2SPCKMAAAQBz3qGXnqqadUW1uryy+/XEVFRZHllVdeiaxTXl6uioq2H/ELL7xQL730kp599llNnjxZf/7zn/Xmm2+edNCrXZLdTuVneFRphq4Oajwk+X32FgUAwADXo56R7kxJsmTJkhPabrjhBt1www09+SrbDBmUog31GQo63HIEW6WGSil7qN1lAQAwYHFvmuOUDEqVZKjBE7ocufaArfUAADDQEUaOUzLIGjdy1JlnNdQRRgAA6E2EkeOEw0iFGZr4rDY+E64BAJCoCCPHsU7TSHv9obv3cpoGAIBeRRg5TmSukZYsq4HTNAAA9CrCyHHCp2l2t4Z7RvbbWA0AAAMfYeQ4yW6nctM97caMEEYAAOhNhJEOlAxK0cHwxGfNRyVfk70FAQAwgBFGOjBkUIrqlKZWp3XKRnXcvRcAgN5CGOmANW7EUI0r32qo41QNAAC9hTDSgfDlvVWO0MRnjBsBAKDXEEY6EL6iZn8gNG6EuUYAAOg1hJEOlIbCyE5feK4RekYAAOgthJEOFIcmPtvTyiysAAD0NsJIB1KTXMpNT2qba4RZWAEA6DWEkU6U5qTqYPuJz0zT3oIAABigCCOdGNo+jPgapJZaewsCAGCAIox0YmhOqlrkUZMz02rgVA0AAL2CMNKJ0hxrrpFDjlyrgUGsAAD0CsJIJ0pDE5/tD4bHjZTbWA0AAAMXYaQTQwdbYWSHLxRGju21sRoAAAYuwkgnCjOT5XYaKg+GTtPUEEYAAOgNhJFOOB2GSgalap8Zuj9NDadpAADoDYSRkyjNSdU+M3TnXk7TAADQKwgjJzE0J6WtZ6T5qOStt7cgAAAGIMLISZQOSlWDUtXoCM01Qu8IAAAxRxg5iaGhuUYqHKFTNQxiBQAg5ggjJxGe+GxPIHRFDT0jAADEHGHkJCJzjbSGL+/lihoAAGKNMHISmcluZae6tT9yeS89IwAAxBphpAtDubwXAIBeRRjpQmlOqvab7WZhNU17CwIAYIAhjHRh+ODUttM0vgap6ai9BQEAMMAQRrowbHCavErSMUeO1VCzx9Z6AAAYaAgjXRg+OE2StF/huUa4ogYAgFgijHRheOjy3p2tg60GBrECABBThJEu5GV4lOJ2qpzLewEA6BWEkS4YhqFhg1NVbhZYDUd321sQAAADDGGkG4YPTtOeYDiM7LS3GAAABhjCSDcMy03VXrPQelG7X/J77S0IAIABhDDSDcNy0nRIWWo2UiQzyBU1AADEEGGkG6wragztN0K9I0d32VoPAAADCWGkG4blWnON7PCH5ho5wrgRAABihTDSDUWZyUpyObQ7MoiVnhEAAGKFMNINDoehoTmp2mMSRgAAiDXCSDcNH5yqPcHwmBFO0wAAECuEkW4aNjhNe8KX99aUS36fvQUBADBAEEa6afjgVFUrW17DY13eW7vP7pIAABgQCCPdNDIvXVGX93JFDQAAMUEY6aYRoct7t/sZxAoAQCwRRrqpMDNZyW5Hu3vUEEYAAIgFwkg3ORyGRuSmt7u8l9M0AADEAmGkB0bmpmlvOIwwZgQAgJggjPTAyLw07QoWWS9q9nL3XgAAYoAw0gMjctNUpUFqMlKty3vpHQEA4LQRRnogfHnvLg2xGg5vs7UeAAAGAsJID4Qv793qD52qIYwAAHDaCCM9kJXiVm56knYGi62GQ2X2FgQAwABAGOmhEblp2mGGwshhwggAAKeLMNJDVhgJjxnZIQWD9hYEAEA/RxjpoZF56So38+U33JK/mRvmAQBwmggjPTQiN00BOXXAET5VwyBWAABOB2Gkh0blWVfUlPlDd+9lECsAAKeFMNJDwwanyeUwtDXA5b0AAMQCYaSH3E6HhuemaUeQic8AAIgFwsgpGJ2Xrp3hK2o4TQMAwGkhjJyCMwrStdMMnaZpPio1Hra3IAAA+rEeh5Fly5bp6quvVnFxsQzD0JtvvnnS9ZcsWSLDME5YKisrT7Vm243OT1eLPKp2FlgN1VvsLQgAgH6sx2GksbFRkydP1pNPPtmj7crKylRRURFZ8vPze/rVfcbo/HRJ0ueBUquherON1QAA0L+5errB7NmzNXv27B5/UX5+vrKzs3u8XV80Ki9dhiFt8pfoC661UtXndpcEAEC/FbcxI2effbaKior0pS99SX//+99Puq7X61VdXV3U0pcku50qGZSismCoZ4QwAgDAKev1MFJUVKSnn35ar732ml577TWVlpbq8ssv1/r16zvdZv78+crKyoospaWlvV1mj52Rn6Et5lDrRfUW7lEDAMApMkzTNE95Y8PQG2+8oWuvvbZH21122WUaOnSofv/733f4vtfrldfrjbyuq6tTaWmpamtrlZmZearlxtQj723Rc8u2qyzldrlMn/TdjVLOCLvLAgCgz6irq1NWVlaXv9+2XNp7/vnna8eOHZ2+7/F4lJmZGbX0NaPz0xWQU/tdnKoBAOB02BJGNm7cqKKiIju+Oma4ogYAgNjo8dU0DQ0NUb0au3fv1saNG5WTk6OhQ4dq3rx5OnDggP7nf/5HkvSf//mfGjFihM466yy1tLTot7/9rRYvXqwPP/wwdnthg3AY2egt1lVu0TMCAMAp6nEYWbt2rb7whS9EXt9///2SpFtuuUULFixQRUWFysvLI+/7fD794Ac/0IEDB5SamqpJkybpo48+ivqM/igz2a3CzGSVNdAzAgDA6TitAazx0t0BMPE25/k12rJtmz5OnisZDunHByV3it1lAQDQJ/TpAawDxdjCDB1StpqcWZIZ5KZ5AACcAsLIaTizIEOSod3OYVYD40YAAOgxwshpGFuYIUna4AuNG6n8zMZqAADonwgjp2F0frochrTOF5qJteITewsCAKAfIoychmS3U8MHp2mTGZp5tfJTpoUHAKCHCCOnaUxhhnaZRfI7kiVfg3R0l90lAQDQrxBGTtOZBRkKyKkDnlFWQ8VGW+sBAKC/IYycpvAg1s/N4VYD40YAAOgRwshpGhMKIyuaSqwGwggAAD1CGDlNwwanyeNyaENraK6Rik+kvj+pLQAAfQZh5DQ5HYbOKEjXNrNEQcMttdRINeVdbgcAACyEkRgYU5CpVrl0KDU8iJVTNQAAdBdhJAbGF1s3/9nmGGk1EEYAAOg2wkgMjC+ywsialtC08AfX21gNAAD9C2EkBsJhZHFDaBDr/rXMxAoAQDcRRmIgK9WtIdkp2mqWKuBKlbx10qGtdpcFAEC/QBiJkfHFmQrIqarMCVbDvtX2FgQAQD9BGImR8KmazY6xVsO+NTZWAwBA/0EYiZHwFTV/awndwXc/YQQAgO4gjMRIuGfkvWOhK2qO7JAaj9hYEQAA/QNhJEZKBqUoI9mlQ4FUebPPsBrpHQEAoEuEkRgxDCPSO3Iwc5LVyCBWAAC6RBiJofC4kc+MMVYDg1gBAOgSYSSGIpOfNYUGsR5YJ/m9NlYEAEDfRxiJoYklWZKkhVUZMtPyJH+LNRsrAADoFGEkhkbnpSvF7VSjL6iGwgusxj3L7S0KAIA+jjASQy6nQ2eFxo3sSJtiNe75m40VAQDQ9xFGYix8qma5f5zVsG+N1NpiY0UAAPRthJEYmxQKI0sOZ0nphVLAy3wjAACcBGEkxiYOyZYkfV5Rp+Dwi63G3ZyqAQCgM4SRGBuZm6Z0j0strUFV5ZxvNTJuBACAThFGYszhMDRhiDWIdb1jgtW4f63ka7KxKgAA+i7CSC+YVJItSVp5LEPKLJGCrVL5CnuLAgCgjyKM9IKJQ6xBrJ8dqJNGfcFq3LHIxooAAOi7CCO9YHKoZ2RLRb1aR15hNe74yL6CAADowwgjvaA0J0U5aUnyBYLanDxFMpzS4W3Ssb12lwYAQJ9DGOkFhmFoSmm2JGltlSmVhq6q2cmpGgAAjkcY6SVThmZLkjaUH5NGh0/VEEYAADgeYaSXnDN0kCRpQ3mNNHqG1bhrieT32VYTAAB9EWGkl0wqzZZhSAdqmlWdNkZKzZV8DdK+1XaXBgBAn0IY6SXpHpfGFGRIkjbsr2s7VbPtfRurAgCg7yGM9KLwuJH15cekcVdbjZ+/KQWDttUEAEBfQxjpRVOOHzeSlC7V7ZcOrLW3MAAA+hDCSC86J9Qz8un+GvkdHmnM/7He2PS6fUUBANDHEEZ60cjcdGUkW3fw3VpZL511nfXG5jc5VQMAQAhhpBc5HEbkEt+P9xy1BrF6sqT6Cq6qAQAghDDSy84fkSNJWrvnmOTySGOvst74nFM1AABIhJFed+4wq2dkzZ6jMk1TmvBV641NrzEBGgAAIoz0usml2UpyOnSo3qvyo03SyC9I6QVS0xFp+4d2lwcAgO0II70s2e3UxJIsSdKa3Uclp0uadKP15sY/2FgZAAB9A2EkDs4b3m7ciCSdfbP1uO0DqaHapqoAAOgbCCNxcN7wdlfUSFL+WGnIVMkMSJ/+ycbKAACwH2EkDqaGBrHuOtyoww1eqzHcO7LxD5Jp2lQZAAD2I4zEQXZqUuSmeWvDvSMTrpdcyVL1ZmnvChurAwDAXoSRODlvhNU7smpXKIykZEuTv249X/Vre4oCAKAPIIzEyfSRuZKkVbuOtDVe8G3rceu70tFdNlQFAID9CCNxcsFI64qarZX1beNG8sZYd/OVKa1+xr7iAACwEWEkTganezS20Bo30mHvyIYXpZZaGyoDAMBehJE4unCUdapmxc52YWTUF6W8cZKvQVr9rE2VAQBgH8JIHF04arAkaVX7MGIY0qU/tJ6v/BW9IwCAhEMYiaPzR+bIYVjzjVTUNre9cdZ1Uu4YK4isetq+AgEAsAFhJI4yk92aOMS6T83K9r0jDqd0+QPW85VPSs018S8OAACbEEbibHpo3MjfdxyJfmP8ddbYEW+ttOKXNlQGAIA9CCNxdtFoa9zI33ccltl+GniHQ/riv1jPV/y3dHS3DdUBABB/hJE4O294jjwuhyrrWrS9uiH6zbFXSSMvlwJe6cN/saU+AADijTASZ8lup6aNtHpHlm07FP2mYUhX/rtkOKWt70g7FtlQIQAA8UUYscGlZ1jjRpYeH0YkKX+sNO1b1vP3fiT5muJYGQAA8UcYscFlZ+ZJktbsPqqW1kAHKzwgZRRJR3dKi/8tztUBABBfPQ4jy5Yt09VXX63i4mIZhqE333yzy22WLFmic845Rx6PR6NHj9aCBQtOodSBY3R+ugozk+X1B7V699ETV0jJlq4OXVGz6tfS3hVxrQ8AgHjqcRhpbGzU5MmT9eSTT3Zr/d27d+uqq67SF77wBW3cuFH33Xef7rjjDn3wwQc9LnagMAxDl55pnao5YdxI2JkzpSnflGRKb94jtdTFr0AAAOLI1dMNZs+erdmzZ3d7/aefflojRozQ448/LkkaN26cli9frieeeEKzZs3qcBuv1yuv1xt5XVc38H6ILz0zT39au7/zMCJJsx6Rdi2Vju2R3por/cP/WINcAQAYQHp9zMjKlSs1Y8aMqLZZs2Zp5cqVnW4zf/58ZWVlRZbS0tLeLjPuLh6dK4chba9u0P5jnQxSTc6SblggOdzSlv+1TtkAADDA9HoYqaysVEFBQVRbQUGB6urq1Nzc3OE28+bNU21tbWTZt29fb5cZd9mpSZo6bJAkafHW6s5XLDnX6iGRpIUPSnuWx6E6AADip09eTePxeJSZmRm1DERXjLNC2qItJwkjknT+ndLEG6SgX3r5ZunQtjhUBwBAfPR6GCksLFRVVVVUW1VVlTIzM5WSktLbX9+nzRiXL8m6aV6j19/5ioYhfeVXUsn5UkuN9IevSQ0nGWsCAEA/0uthZPr06Vq0KHom0YULF2r69Om9/dV93qi8dA3NSZUvENTfth8++cruFOmmP0qDhks1e61AwhU2AIABoMdhpKGhQRs3btTGjRslWZfubty4UeXl5ZKs8R5z5syJrH/33Xdr165d+ud//mdt3bpVv/71r/WnP/1J3//+92OzB/2YYRi6ItQ7smhLVRdrS0rLlW5+TUrNlSo2Sn/8utTa8bgbAAD6ix6HkbVr12rKlCmaMmWKJOn+++/XlClT9OCDD0qSKioqIsFEkkaMGKF3331XCxcu1OTJk/X444/rt7/9baeX9SaaGaFxI38tq1YwaHaxtqTc0dI/vi55MqW9f5de+SaBBADQrxlm1H3s+6a6ujplZWWptrZ2wA1m9fmDmvqvC1Xv9ev1b1+oc4YO6t6Ge1dIv/+q5G+WRlwqff2Pkie9d4sFAKAHuvv73SevpkkkSS6HLh9rnar5YFNl9zccdqH0zdekpHRp9zLp99dJjV2MOwEAoA8ijPQBV55VKEn6y6ZK9aijavhF0py3rMnR9q+Rnr1cqvi0d4oEAKCXEEb6gMvH5CnZ7VD50SZtrujhFTIl50q3L5RyRkq1+6TnZkrr/0fq+2ffAACQRBjpE9I8Ll12Zp4k6f2enKoJyxsj3blYGnWFNYbkf79jDWzltA0AoB8gjPQRsycUSbJO1ZySlEHSza9KM35m3ctm6zvSr6dL2xfGsEoAAGKPMNJHfHFcvtxOQzuqG7S9qv7UPsThlC6+z+olyRsrNVZbk6O9/T2p8UhM6wUAIFYII31EZrJbF4/OlSS999kp9o6EFU2S7loiTbvHer1ugfTLKdKK/2ZOEgBAn0MY6UP+z0TrVM3bnx7s2VU1HXGnSLMflW59TyqcKHlrpQ//P+k/J0p/e1xqqY1BxQAAnD7CSB8ya0KhklwO7ahu0JaKUzxVc7zhF0l3LbVutJc9VGo8JC16WHpigvXY0MUdgwEA6GWEkT4kM9mtL46xJkD7308Oxu6DHU7pnDnSd9ZL1z0j5Y6RvHVWD8kTZ0lvzpUqP4vd9wEA0AOEkT7mK2cXS5Le/uRg9+5V0xNOtzT569K3V0k3/kEacq4U8EkbX5Sevlha8GVpy9tSoDW23wsAwEm47C4A0b44Nl/pHpcO1DRrffkxnTs8J/Zf4nBI475sLfs+llb9Wtr8lrTnb9aSkiNNuF6a9A9SyXmSYcS+BgAAQugZ6WOS3U7NPMu6k29MT9V0pvQ86YYXpPs+lS66T0rLl5qPSh//RnruS9ZVOB/+RNq1RGpt6f16AAAJh7v29kFLtx3SLc+vUU5aklbNu0JJrjhmxoBf2r1E+vRP0pZ3pNbGtvdcKdLwi6VRX5RGXCLln2X1sgAA0IHu/n5zmqYPumjUYOVleHSo3qslZdWaGbqRXlw4XdLoGdbia5TK/iLtWCTtXCw1VEo7FlqLJCVnS8MusgLK8IulggmEEwBAj9Ez0kc98t4WPbtsl2aOL9Czc861uxzrxnvVm61QsvOv0r7Vkq8hep3kbKl0mlQ02Zp4rWiylFXKmBMASFDd/f0mjPRRZZX1mvWfy+RyGFr94ys0ON1jd0nRAn6p4pPQoNflUvnKE8OJZAWUoklS4SSr5yT3TCn3DCk5MY4jACQywsgAcPWvluuzA7V66Orxuu2iEXaXc3LhcHJgnfVY+YlUvUUK+jteP6PICiW5Y9oCSu6ZUmYxPSkAMEAwZmQA+NrUEn12oFavrd/f98OI0yWVTLWWML/XCiSVn1oB5VCZdHib1FAl1VdYy+5l0Z+TlN4WTCKPY6SckZIrKb77BACIC3pG+rBjjT6d/8hHag2Yeve7F+us4iy7S4qN5hrp8HYrmBzeFnpeJh3dLZmBjrcxnNKg4VY4yTszFFJCgSVlUDyrBwB0Ez0jA8CgtCTNHF+odz+r0Mtr9ulfrx0gYSQl25rfpPS86Ha/Tzq22wooh8raBZbtkq9eOrrTWrb9JXq7tPzonpRwWMks4eoeAOgH6Bnp45ZvP6xvPrdaGckurfnxDKUkOe0uKf5MU6qvtHpPju9RqTvQ+XauFCl3dNupnnBYGTzKuqsxAKBX0TMyQFw4arBKc1K072iz3v2sQl+bWmJ3SfFnGFJmkbWMvDz6PW99KKCEQ0oosBzZKfmbrRsAnnATQEMaNCz6VE94IG3a4HjtFQAghDDSxzkchr5+3lA99kGZ/rimPDHDyMl4MqQh51hLewG/VLO3bdBs+7DSUisd22Mt2z+M3i4lp+NxKdnDrLsfAwBijtM0/UB1XYumP7pYgaCpD79/qc4syLC7pP7LNKXGQ9GnesLjU2rLO9/O6ZEGj253hU8opAweLXnS41c/APQjnKYZQPIzkzVjXL4++LxKf1i1Vz+7ZoLdJfVfhiGl51vL8Iuj3/M1SUd2tAsq29pOAQW8UvXn1nK8zJIOLkc+U8ooZM4UAOgGekb6ifBA1rQkp1b9+AplJLvtLilxBANSTXkHlyNvk5oOd75dUkbHIYU5UwAkCHpGBpiLRg/WyLw07TrUqDc2HNCc6cPtLilxOJxSzghrOXNm9HtNRzsOKcd2W5cjH1xvLe21nzPl+NM+qTlx2y0A6CvoGelHFvx9t3769maNzk/Xwu9fKoNTAH2X32tN4nZ8SAnPmdIZT5Z1pc+g4ScuWaX0qADoV+gZGYCun1qixz4o047qBq3ceUQXjs61uyR0xuWR8sdaS3uROVM6CCl1+yVvrTV9fuWnJ36m4ZAyh1j378koCj0WShnF1mXPGaElKTU++wgAMUIY6Ucykt267pwhenFVuZ7/+x7CSH8UNWfKZdHv+Zqsy5HDlx0fv/hbpNp91nIyyVnWrLTp+VJabrvneaHHfCk9z3qdlNYbewkAPUIY6Wduu2iE/rC6XB9tqdKO6gaNzuey0gEjKVXKH2ctxzNN6waDx/a23WSw7qDVyxJ5XiG1NlnzqLTUSke2d/2d7rRQMGkXWNLyrCn7k7PbHpOz2p4npXGVEICYIoz0M6Py0jVjXIEWbq7Sb/+2S49eP8nukhAPhhE6JVPY+TqmKXnrrIDSUC01VksNh0KP1db8Ko2H2tr8LVJro3Ss0ep56S6H68SAkhJ67cmQPJnWkhx69GSEnmdYY2I8GYx9ARCFMNIP3X3ZSC3cXKXX1x/Q/V86U/mZyXaXhL7AMKxAkJwl5Y05+bqmaU2l33ioXVAJh5dDUkuN1bvSXGM9Dz8G/dbSdPjklzV3xZXcQVBpH2IyjnseDjrpVs9MUrrkTrXuMUQvDdDvEUb6oanDcnTusEFau/eYFqzYo3++cmzXGwHtGYb1Q5+cad04sDtM0zoNFA4mx4cVb53UUmc9Rp7Xh17XW69bG63P8rdYS2P16e5IKJyEFnf4eWp0aIlaJ/TalRwKNMnWTRXd7RZXctsjYQfodYSRfuquS0dq7e/X6fer9urbXxitdA+HEr3MaPfDnzXk1D4j4LcubW4fVCLPa9tCS0fvtdRJvkZr8TeHPtCUfA3W0ltcKVZgcae2hZT2gcWd0sE6qdapKGeS5HSHHpOsU1zODtqdnbQfvz7BCAMUv2D91IxxBZFJ0F5eU647Lhlpd0lA15wuKWWQtZyOYMDqpfE1WUGktaktqPgaQ68bQu83Wj0yvsbo9VtbrFDTGlr8LW3Pg61t3+VvtpbmY6dXcyw43D0LL5FHd/fXlWGFHsNhfafhaPfa6OJ1u/W7XNeQFJrmyjRP8lzW61N+HqvP6SvfpRh9TgfPz79Lyi6VHQgj/ZTDYeiuS0bq/77+mZ5fvlu3XDhcbqfD7rKA+HA4Q2NIMiQVxP7zA/5QUGmxgkv7oNJZgIm8F9om4Gu3+Ns9b7Ueg61tzyOP7df1nlhXsNVaWk98Czht475CGEHPXTtliB5fuE0Ha1v0zqcHdd2UErtLAgYGp0tyhsOOTUzT6gEKh5RgB4Em0HpckOko6HSxfvC4QBTumTCD7Z6Hl2D0ex2+Vgfvd7Ju5LST0QvP1fk6kfdO57lOYf1T2R+d+rY9rS+jF4J9NxFG+rFkt1O3XTRcP3+/TM8s3aVrzx7CFPHAQGEYoVDkksSsuhjY6Nfv526eNkxpSU5trazXh5ur7C4HAIAeI4z0c1kpbv3TxSMkSf/xQZkCwT5/30MAAKIQRgaAOy4ZqawUt7ZXN+itjQfsLgcAgB4hjAwAWSlu3X2ZNXHVEx9tk88ftLkiAAC6jzAyQNx64XDlZXi072izXvm43O5yAADoNsLIAJGS5NR3vzhakvTLxTvU5PPbXBEAAN1DGBlAbjxvqEpzUnSo3qvfrdhrdzkAAHQLYWQASXI59P0ZZ0qSnl66U7XNTNMIAOj7CCMDzDVnD9GZBemqbW7VM0t32l0OAABdIowMME6HoR/OHCNJem75bu0/1mRzRQAAnBxhZAD60vgCXTAyR15/UP/+fpnd5QAAcFKEkQHIMAz95MvjZRjS258c1Lq9R+0uCQCAThFGBqizirN047nWraB/9vZmpokHAPRZhJEB7AczxyjD49Kn+2v10homQgMA9E2EkQEsL8OjH86yBrP+/P2tOlTvtbkiAABORBgZ4L55wTBNHJKl+ha//t+7m+0uBwCAExBGBjinw9D/u26CDEN6c+NBLd12yO6SAACIQhhJAJNKsnXrhcMlSQ/8+VNmZgUA9CmEkQTxo1ljNHxwqirrWvRv73C6BgDQdxBGEkRqkkv/ccNkGYb06rr9Wry1yu6SAACQRBhJKOcOz9EdF4+QJP3f1z5TTZPP5ooAACCMJJwfzByjkXlpqq736mdvc7oGAGA/wkiCSXY79fgNk+UwpDc2HNAHn1faXRIAIMERRhLQlKGD9K3LRkmSHnjtUx2saba5IgBAIiOMJKj7ZpyhSSVZqmlq1dyX1svnD9pdEgAgQRFGEpTH5dST3zhHGckubSiv0c/f32p3SQCABEUYSWClOal6/IbJkqTfLt+t9zcxfgQAEH+nFEaefPJJDR8+XMnJyZo2bZrWrFnT6boLFiyQYRhRS3Jy8ikXjNiaeVah7rzEutz3R3/+ROVHmmyuCACQaHocRl555RXdf//9euihh7R+/XpNnjxZs2bNUnV1dafbZGZmqqKiIrLs3bv3tIpGbP3zlWN1ztBs1bf49e2X1qmlNWB3SQCABNLjMPKLX/xCd955p2677TaNHz9eTz/9tFJTU/X88893uo1hGCosLIwsBQUFp1U0YsvtdOi/v3GOBqW6telAnea9/plM07S7LABAguhRGPH5fFq3bp1mzJjR9gEOh2bMmKGVK1d2ul1DQ4OGDRum0tJSXXPNNfr8889P+j1er1d1dXVRC3pXcXaK/vsb58jpMPTGhgP69ZKddpcEAEgQPQojhw8fViAQOKFno6CgQJWVHQ9+HDNmjJ5//nm99dZbevHFFxUMBnXhhRdq//79nX7P/PnzlZWVFVlKS0t7UiZO0UWjc/Wzr5wlSXrsgzK98+lBmysCACSCXr+aZvr06ZozZ47OPvtsXXbZZXr99deVl5enZ555ptNt5s2bp9ra2siyb9++3i4TId+8YJhuvXC4JOn7r2zU8u2H7S0IADDg9SiM5Obmyul0qqoq+o6vVVVVKiws7NZnuN1uTZkyRTt27Oh0HY/Ho8zMzKgF8fOTL4/X/5lYqNaAqbt+v1af7KuxuyQAwADWozCSlJSkqVOnatGiRZG2YDCoRYsWafr06d36jEAgoM8++0xFRUU9qxRx43QYeuLGs3Xx6Fw1+QK69YU12lHdYHdZAIABqsenae6//3795je/0e9+9ztt2bJF99xzjxobG3XbbbdJkubMmaN58+ZF1n/44Yf14YcfateuXVq/fr2++c1vau/evbrjjjtitxeIOY/Lqaf/caoml2TpWFOr/vG51dzDBgDQK1w93eDGG2/UoUOH9OCDD6qyslJnn3223n///cig1vLycjkcbRnn2LFjuvPOO1VZWalBgwZp6tSpWrFihcaPHx+7vUCvSPe49MJt5+trT6/QrkON+uZzq/XynRcoP5NJ6wAAsWOY/WBCibq6OmVlZam2tpbxIzY4UNOsG55aoYO1LRqZm6aX7rxAhVkEEgDAyXX395t706BLQ7JT9PJd0zUkO0W7DjfqxmdX6gCnbAAAMUIYQbcMHZyql++6QKU5Kdp7pEk3PrNS+45yHxsAwOkjjKDbSnNS9cpd0zV8cKr2H2vWjc+s1O7DjXaXBQDo5wgj6JHi7BS98q3pGpmXpoO1Lbr+qRVat/eY3WUBAPoxwgh6rCAzWa/cNV0Th2TpaKNPN/1mld77rMLusgAA/RRhBKckL8Ojl++6QDPG5cvnD+rbf1ivZ5ft5G6/AIAeI4zglKV5XHrmH8/VLdOHSZIeeW+r/uXNTfL5gzZXBgDoTwgjOC1Oh6GffuUs/eTL42UY0h9Wl+vGZ1cyWysAoNsIIzhthmHo9otH6Df/eK4ykl3aUF6jq375Ny3ddsju0gAA/QBhBDEzY3yB3v3OJZowJFPHmlp16wtr9MTCbQoEGUcCAOgcYQQxNXRwqv5894X6xrShMk3pvxZt102/WaXyI0yQBgDoGGEEMZfsduqR6ybqiRsnKzXJqTW7j+rK/1qmF1ft5WobAMAJCCPoNddNKdH737tU00bkqMkX0L+8uUlznl/D4FYAQBTu2oteFwyaWrBij/79/a3y+oNK97h0/5fO1Jzpw+RykocBoCPBoCl/0FQgaKo1GFQg0PbaHwzKf9zrQNBUayD6dds6wbbPCkS/ttYJ6tqzhyg/M7Z3ZO/u7zdhBHGz61CDfvjqJ1pfXiNJGleUqX+79ixNHZZjb2EAEkIgaMrnD8rnD8obCMjbGpQvEIy0+QJBeVuDag2EF+tHujVgqjUQlD8QlC9gyt/u/daA9aMe3sYfMOULPUZ/RvvPMaO/IxBUa9A8bvug4j32/41vX6gpQwfF9DMJI+iTgkFTL3+8T//+/lbVNrdKkm6YWqIHZo9VbrrH5uoA9KbWQFAtrQG1tFqPXr/1vLk1ENUeXrz+YGTx+YPy+gNRwcHX7j0rYJx8vYFyZZ/bacjpMORyOOR0GCe8djkMuZyGnA6HXA7jpOu0f/2dK87QiNy0mNZKGEGfdqTBq39/f6v+tHa/JCktyanbLxmpOy4Zocxkt83VAYklEDTV3BpQk9evJl9AjT6/mn0BNfoCavb51egNtAsM7UJDuzDh7ajd1xY4WloD8vehMGAYUpLTIY/LoSSXM/ToUJLTIbfLkNvpCC3Wc5ej3XOnoaTQY/v1otdxKMlpyHXC57Rt07Z99KPL6ZDbYW1rBYboINGfEEbQL6zbe1Q//d/N+uxArSQpO9Wtb18+SnOmD1ey22lzdUDfYppWaGho8ave61eTt31wsIJEk9evptaAmrwB63W4Pep5dFtLa/xv4ZDsdijZ7VSyy9n23O08od3jclohIbS0Dw2eSJsz0nb8eh6XQ0lOZ/S2LisUGEb/+mHvjwgj6DdM09RfNlXqPz4s065DjZKkgkyPbrlwuL5x/lBlpybZXCFwegJBU40+vxpa/Grw+lUferRetx732goaDce3tbSqwevv1XEEhiGlJbmUkuRUWpJTKUmu0KNTKW7r8cTw0P61QylupzzHhYyU49bzuBwEgQRBGEG/4w8E9fqGA/qvj7brQOjy3xS3U1+bWqLbLhqukXnpNleIRNXSGlBtc2vb0mQ91oRe1zW3dhAm2toafYGY1mMYUnqSS+nJ4eDQFiBSOwkTaR6XUkPvW4/Rz9M8LkICYo4wgn7L6w/o7U8q9Nzy3dpSUSfJ+uN78ehcfW1qiWadVcgpHPSYzx8MhQnfCcGipt3ruuZW1TS1Rq3jjdGdqN1OQxnJbqV7XNaS7FJG6DHqtcel9NB6GckupYXaMkLrpSY5CQ3oFwgj6PdM09TKXUf03N92a9HW6kh7hselL08u0vXnlOicoYPk6GcDunDqWgNB1TWf2CtR20GAaN+DUdvcqubW0+udcBhSVoo7smSmuJWdmqSsFJcyk91WyIgKE9EBIj3ZJY+LEI3EQhjBgLL3SKNeW39Ar63bHzmFI0m56Un6wph8XTGuQJeckas0j8vGKtEV0zTV6AuorrlVdS1WWKhr8UcCRV1Lq+qa/dZ77YJG+PF0T3cYhpSZ7I4KFVkpbmWlRr/Obhc4wu+nJ7kIvkAPEUYwIAWDplbtPqI/r9uvhZ9Xqd7rj7yX5HJo6tBBOnf4IJ07PEdThmZzmXAvaDvd0T5AhJYOgkXUOi3+mMz1kOFxnRAgOg4VSVGvM5IJFEA8EUYw4Pn8QX2856g+2lKlRVuqVX40+s7AhiGNKcjQuKJMnVmQoTGF6TqzIEPFWSkJ/4Pk9QeiehyiT2v4o8PGceuc7ukOyRo7kZXitk5vhHshkl2RnojMZLcyQ6c/Mo/rrchIdnEbAaCfIIwgoZimqZ2HGrVm91Gt3XtUa/ccOyGchCW5HBqSnaIh2SkqGZSi4uwU5aZ7NDg9SYPTkjQ43aOsFLfSPE4lOfve1QXHzzVx4uWixwcK3wljKU53XgnDiO6dyEx2R05/hENEVmp0qAif9shMdivZ3ff+dwUQe4QRJLzquhZ9sr9W26rqVVZZr21V9dp5qEGtge7/J+9yGErzWJdHpnmsqxrCMy+2Tancfsrl6KmWHYYh05RMWd9pPVfkuWQq/C8waJrtZrAMTZcdntXSH1Czz5r9MlZzTXQ2fiLz+FMfHSzpya5+NxMkgPgjjAAdaA0EVVnbov3HmnWgplkHjjXrYE2zjjT6dKTRqyMNPh1u8KopxvNC9AaHodDVGu6oqzfSPa6uA0WqWxkexk8A6F3d/f3m0gMkFLfTodKcVJXmpJ50PX8gqMbQVNmNXuveHI1ea/Kq8N02A6Hbe/tDt+Nuu3W3dRdOf9BU0DRlSJJhyLAeJEmGDBmGotsMo22WSteJM1t6Qm3MNQFgoCGMAB1wOR3KSnEoK4WrcQCgtzEkHQAA2IowAgAAbEUYAQAAtiKMAAAAWxFGAACArQgjAADAVoQRAABgK8IIAACwFWEEAADYijACAABsRRgBAAC2IowAAABbEUYAAICt+sVde03TlCTV1dXZXAkAAOiu8O92+He8M/0ijNTX10uSSktLba4EAAD0VH19vbKysjp93zC7iit9QDAY1MGDB5WRkSHDMGL2uXV1dSotLdW+ffuUmZkZs8/tS9jH/m+g75/EPg4EA33/pIG/j72xf6Zpqr6+XsXFxXI4Oh8Z0i96RhwOh0pKSnrt8zMzMwfkf1jtsY/930DfP4l9HAgG+v5JA38fY71/J+sRCWMAKwAAsBVhBAAA2Cqhw4jH49FDDz0kj8djdym9hn3s/wb6/kns40Aw0PdPGvj7aOf+9YsBrAAAYOBK6J4RAABgP8IIAACwFWEEAADYijACAABsRRgBAAC2Sugw8uSTT2r48OFKTk7WtGnTtGbNGrtLOiXz58/Xeeedp4yMDOXn5+vaa69VWVlZ1DqXX365DMOIWu6++26bKu65n/70pyfUP3bs2Mj7LS0tmjt3rgYPHqz09HRdf/31qqqqsrHinhs+fPgJ+2gYhubOnSup/x3DZcuW6eqrr1ZxcbEMw9Cbb74Z9b5pmnrwwQdVVFSklJQUzZgxQ9u3b49a5+jRo7r55puVmZmp7Oxs3X777WpoaIjjXpzcyfaxtbVVDzzwgCZOnKi0tDQVFxdrzpw5OnjwYNRndHTcH3300TjvSee6Oo633nrrCfVfeeWVUev05ePY1f519G/SMAw99thjkXX68jHszu9Dd/5+lpeX66qrrlJqaqry8/P1ox/9SH6/P2Z1JmwYeeWVV3T//ffroYce0vr16zV58mTNmjVL1dXVdpfWY0uXLtXcuXO1atUqLVy4UK2trZo5c6YaGxuj1rvzzjtVUVERWX7+85/bVPGpOeuss6LqX758eeS973//+3r77bf16quvaunSpTp48KC++tWv2lhtz3388cdR+7dw4UJJ0g033BBZpz8dw8bGRk2ePFlPPvlkh+///Oc/1y9/+Us9/fTTWr16tdLS0jRr1iy1tLRE1rn55pv1+eefa+HChXrnnXe0bNky3XXXXfHahS6dbB+bmpq0fv16/eQnP9H69ev1+uuvq6ysTF/5yldOWPfhhx+OOq7f+c534lF+t3R1HCXpyiuvjKr/j3/8Y9T7ffk4drV/7feroqJCzz//vAzD0PXXXx+1Xl89ht35fejq72cgENBVV10ln8+nFStW6He/+50WLFigBx98MHaFmgnq/PPPN+fOnRt5HQgEzOLiYnP+/Pk2VhUb1dXVpiRz6dKlkbbLLrvM/N73vmdfUafpoYceMidPntzhezU1Nabb7TZfffXVSNuWLVtMSebKlSvjVGHsfe973zNHjRplBoNB0zT79zGUZL7xxhuR18Fg0CwsLDQfe+yxSFtNTY3p8XjMP/7xj6ZpmubmzZtNSebHH38cWecvf/mLaRiGeeDAgbjV3l3H72NH1qxZY0oy9+7dG2kbNmyY+cQTT/RucTHS0T7ecsst5jXXXNPpNv3pOHbnGF5zzTXmF7/4xai2/nQMj/996M7fz/fee890OBxmZWVlZJ2nnnrKzMzMNL1eb0zqSsieEZ/Pp3Xr1mnGjBmRNofDoRkzZmjlypU2VhYbtbW1kqScnJyo9j/84Q/Kzc3VhAkTNG/ePDU1NdlR3inbvn27iouLNXLkSN18880qLy+XJK1bt06tra1Rx3Ps2LEaOnRovz2ePp9PL774ov7pn/4p6k7V/f0Yhu3evVuVlZVRxywrK0vTpk2LHLOVK1cqOztb5557bmSdGTNmyOFwaPXq1XGvORZqa2tlGIays7Oj2h999FENHjxYU6ZM0WOPPRbT7u94WLJkifLz8zVmzBjdc889OnLkSOS9gXQcq6qq9O677+r2228/4b3+cgyP/33ozt/PlStXauLEiSooKIisM2vWLNXV1enzzz+PSV394q69sXb48GEFAoGo/2ElqaCgQFu3brWpqtgIBoO67777dNFFF2nChAmR9m984xsaNmyYiouL9emnn+qBBx5QWVmZXn/9dRur7b5p06ZpwYIFGjNmjCoqKvSzn/1Ml1xyiTZt2qTKykolJSWd8Ae+oKBAlZWV9hR8mt58803V1NTo1ltvjbT192PYXvi4dPRvMPxeZWWl8vPzo953uVzKycnpl8e1paVFDzzwgG666aaoO6J+97vf1TnnnKOcnBytWLFC8+bNU0VFhX7xi1/YWG33XXnllfrqV7+qESNGaOfOnfrxj3+s2bNna+XKlXI6nQPqOP7ud79TRkbGCaeA+8sx7Oj3oTt/PysrKzv8txp+LxYSMowMZHPnztWmTZuixlNIijo/O3HiRBUVFemKK67Qzp07NWrUqHiX2WOzZ8+OPJ80aZKmTZumYcOG6U9/+pNSUlJsrKx3PPfcc5o9e7aKi4sjbf39GCay1tZW/cM//INM09RTTz0V9d79998feT5p0iQlJSXpW9/6lubPn98v7oHy9a9/PfJ84sSJmjRpkkaNGqUlS5boiiuusLGy2Hv++ed18803Kzk5Oaq9vxzDzn4f+oKEPE2Tm5srp9N5wmjhqqoqFRYW2lTV6bv33nv1zjvv6K9//atKSkpOuu60adMkSTt27IhHaTGXnZ2tM888Uzt27FBhYaF8Pp9qamqi1umvx3Pv3r366KOPdMcdd5x0vf58DMPH5WT/BgsLC08YUO73+3X06NF+dVzDQWTv3r1auHBhVK9IR6ZNmya/3689e/bEp8AYGzlypHJzcyP/XQ6U4/i3v/1NZWVlXf67lPrmMezs96E7fz8LCws7/Lcafi8WEjKMJCUlaerUqVq0aFGkLRgMatGiRZo+fbqNlZ0a0zR177336o033tDixYs1YsSILrfZuHGjJKmoqKiXq+sdDQ0N2rlzp4qKijR16lS53e6o41lWVqby8vJ+eTxfeOEF5efn66qrrjrpev35GI4YMUKFhYVRx6yurk6rV6+OHLPp06erpqZG69ati6yzePFiBYPBSBDr68JBZPv27froo480ePDgLrfZuHGjHA7HCac2+ov9+/fryJEjkf8uB8JxlKzeyqlTp2ry5MldrtuXjmFXvw/d+fs5ffp0ffbZZ1GhMhysx48fH7NCE9LLL79sejwec8GCBebmzZvNu+66y8zOzo4aLdxf3HPPPWZWVpa5ZMkSs6KiIrI0NTWZpmmaO3bsMB9++GFz7dq15u7du8233nrLHDlypHnppZfaXHn3/eAHPzCXLFli7t692/z73/9uzpgxw8zNzTWrq6tN0zTNu+++2xw6dKi5ePFic+3ateb06dPN6dOn21x1zwUCAXPo0KHmAw88ENXeH49hfX29uWHDBnPDhg2mJPMXv/iFuWHDhsiVJI8++qiZnZ1tvvXWW+ann35qXnPNNeaIESPM5ubmyGdceeWV5pQpU8zVq1eby5cvN8844wzzpptusmuXTnCyffT5fOZXvvIVs6SkxNy4cWPUv83wFQgrVqwwn3jiCXPjxo3mzp07zRdffNHMy8sz58yZY/OetTnZPtbX15s//OEPzZUrV5q7d+82P/roI/Occ84xzzjjDLOlpSXyGX35OHb136lpmmZtba2ZmppqPvXUUyds39ePYVe/D6bZ9d9Pv99vTpgwwZw5c6a5ceNG8/333zfz8vLMefPmxazOhA0jpmmav/rVr8yhQ4eaSUlJ5vnnn2+uWrXK7pJOiaQOlxdeeME0TdMsLy83L730UjMnJ8f0eDzm6NGjzR/96EdmbW2tvYX3wI033mgWFRWZSUlJ5pAhQ8wbb7zR3LFjR+T95uZm89vf/rY5aNAgMzU11bzuuuvMiooKGys+NR988IEpySwrK4tq74/H8K9//WuH/13ecsstpmlal/f+5Cc/MQsKCkyPx2NeccUVJ+z3kSNHzJtuuslMT083MzMzzdtuu82sr6+3YW86drJ93L17d6f/Nv/617+apmma69atM6dNm2ZmZWWZycnJ5rhx48xHHnkk6ofcbifbx6amJnPmzJlmXl6e6Xa7zWHDhpl33nnnCf+nri8fx67+OzVN03zmmWfMlJQUs6am5oTt+/ox7Or3wTS79/dzz5495uzZs82UlBQzNzfX/MEPfmC2trbGrE4jVCwAAIAtEnLMCAAA6DsIIwAAwFaEEQAAYCvCCAAAsBVhBAAA2IowAgAAbEUYAQAAtiKMAAAAWxFGAACArQgjAADAVoQRAABgq/8ftQ9Eh+X+WRIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 구현\n",
        " RAM이 꽉찰수록 연산 속도가 현저하게 떨어진다.\n",
        "lambdaUVZ 작을수록 ovefirt 돼서 사실 잘되는 건줄 알았는데 0.001보다 0.01이 훨씬 성능 좋음"
      ],
      "metadata": {
        "id": "qUrb9JLpKzRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_toy = np.array([\n",
        "    [5, 2, 0, 3, 0, 4, 0, 0],\n",
        "    [4, 3, 0, 0, 5, 0, 0, 0],\n",
        "    [4, 0, 2, 0, 0, 0, 2, 4],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [5, 1, 2, 0, 4, 3, 0, 0],\n",
        "    [4, 3, 0, 2, 4, 0, 3, 5]\n",
        "], dtype=float)\n",
        "\n",
        "\n",
        "trust_toy = np.array([\n",
        "            [0, 0, 0, 0, 0, 0],\n",
        "            [0, 0, 0, 0, 1.0, 0.8],\n",
        "            [0.8,0, 0,0,0,0],\n",
        "            [0.8, 1.0, 0, 0, 0.6, 0],\n",
        "            [0,0, 0.4, 0, 0, 0.8],\n",
        "            [0,0,0,0,0,0]])\n",
        "\n",
        "# Apply scaling only to nonzero elements\n",
        "scaled_train_rating_matrix_toy = np.zeros_like(train_toy, dtype=float)\n",
        "\n",
        "for i in range(6):\n",
        "  for ii in range(8):\n",
        "    if train_toy[i,ii]:\n",
        "      scaled_train_rating_matrix_toy[i, ii] = float((train_toy[i, ii] - 1.0) / 4.0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9C4U6ORGfP56"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 필요한 함수들\n",
        "def g(x):\n",
        "  return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "def g_prime(x):\n",
        "  return g(x) * (1- g(x))\n",
        "\n",
        "class SOREC(nn.Module):\n",
        "  def __init__(self, train_R = scaled_train_rating_matrix_full, test_R = scaled_test_rating_matrix_full, trust = ui_uk_matrix, l=10, lambC = 10, lambdaUVZ =0.001, learning_rate=1e-3, epochs= 5):\n",
        "    '''\n",
        "    SOREC\n",
        "    논문에서는 gradient descent 직접 업데이트하는 방식\n",
        "    구현은 pytorch의 loss.backward()\n",
        "    '''\n",
        "    super(SOREC, self).__init__()\n",
        "\n",
        "    # 논문은 특이하게 m이 user 수, n이 item 수\n",
        "    self.m, self.n = train_R.shape # Rating\n",
        "    self.test_n, self.test_m = test_R.shape\n",
        "\n",
        "    self.latent_dimension = l\n",
        "\n",
        "    self.train_R = train_R # 80            (100, 1000)\n",
        "    self.test_R = test_R   # 20 비율       (100, 1000)\n",
        "    self.trust = trust     # trust ratings (100, 100)\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.epoch = epochs\n",
        "    self.lambdaC = lambC\n",
        "    self.lambdaUVZ = lambdaUVZ # 공통으로 사용\n",
        "\n",
        "    # 직접 gradient 각각 update\n",
        "    self.U = nn.Parameter(torch.randn(self.latent_dimension, self.m)) # (l, m)\n",
        "    self.Z = nn.Parameter(torch.randn(self.latent_dimension, self.m)) # (l, m)\n",
        "    self.V = nn.Parameter(torch.randn(self.latent_dimension, self.n)) # (l, n)\n",
        "\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), lr= self.lr)\n",
        "\n",
        "  def get_complete_matrix(self):\n",
        "    self.completed_rating_matrix  = torch.matmul(self.U.T, self.V)\n",
        "    return self.completed_rating_matrix\n",
        "\n",
        "  def forward_user_item(self, u):\n",
        "    # user 들어올 때마다 모든 item에 대한 rating 차이 구하기\n",
        "    predicted_rating = torch.matmul(self.U[:, u].T, self.V) # (l,) (l, n) => (n)\n",
        "    loss = 0\n",
        "    for v in range(self.n):\n",
        "      # R이 있는 경우만\n",
        "      if self.train_R[u, v]:\n",
        "        loss += (self.train_R[u, v] - g(predicted_rating[v])) ** 2\n",
        "        #print(\"u, v,\", u, v, (self.train_R[u, v] - g(predicted_rating[v])) ** 2)\n",
        "\n",
        "    return loss / 2\n",
        "\n",
        "  def forward_social(self, u):\n",
        "    # user 들어올 때마다 trusted user 대한 trust 차이 구하기\n",
        "    predicted_trust = torch.matmul(self.U[:, u].T, self.Z) # (m)\n",
        "    loss = 0\n",
        "    for z in range(self.m):\n",
        "      if self.trust[u, z]:\n",
        "        loss += (self.trust[u, z] - g(predicted_trust[z])) ** 2\n",
        "\n",
        "    return self.lambdaC * loss / 2\n",
        "\n",
        "  def test_accuracy(self):\n",
        "    completed_rating_matrix = torch.matmul(self.U.T, self.V)\n",
        "    mae_loss = 0\n",
        "    test_num = 0\n",
        "    for u in range(self.m):\n",
        "      for v in range(self.n):\n",
        "        if self.test_R[u, v]:\n",
        "          test_num += 1 # .2\n",
        "          mae_loss += abs(completed_rating_matrix[u, v] - self.test_R[u, v])\n",
        "\n",
        "    return mae_loss / test_num\n",
        "\n",
        "  def train_accuracy(self):\n",
        "    completed_rating_matrix = torch.matmul(self.U.T, self.V)\n",
        "    mae_loss = 0\n",
        "    train_num = 0\n",
        "    for u in range(self.m):\n",
        "      for v in range(self.n):\n",
        "        if self.train_R[u, v]:\n",
        "          train_num += 1 # .8\n",
        "          mae_loss += abs(completed_rating_matrix[u, v] - self.train_R[u, v])\n",
        "\n",
        "    return mae_loss / train_num\n",
        "\n",
        "\n",
        "  def fit(self):\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "\n",
        "    for epoch in range(self.epoch):\n",
        "      total_loss = 0\n",
        "      for u in range(self.m):\n",
        "\n",
        "        # user-item matrix loss\n",
        "        loss1 = self.forward_user_item(u)\n",
        "\n",
        "        # trust matrix loss\n",
        "        loss2 = self.forward_social(u)\n",
        "\n",
        "        total_loss = loss1 + loss2 + self.lambdaUVZ * (torch.sum(self.U ** 2) + torch.sum(self.V ** 2) + torch.sum(self.Z ** 2))\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "      test_mae = self.test_accuracy()\n",
        "      train_mae = self.train_accuracy()\n",
        "\n",
        "      train_loss_list.append(train_mae)\n",
        "      test_loss_list.append(test_mae)\n",
        "\n",
        "      if epoch % 200 == 0:\n",
        "\n",
        "        print(f'Epoch [{epoch}/{self.epoch}], total_loss: {total_loss}, train_mae: {train_mae}, test_mae: {test_mae}')\n",
        "\n",
        "\n",
        "    return train_loss_list, test_loss_list\n"
      ],
      "metadata": {
        "id": "dqB7cdzmcNNs"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scaled_train_rating_matrix_toy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TceVHfLdUu35",
        "outputId": "0b2d0d3b-15d5-4095-daa0-11eebed55be0"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.   0.25 0.   0.5  0.   0.75 0.   0.  ]\n",
            " [0.75 0.5  0.   0.   1.   0.   0.   0.  ]\n",
            " [0.75 0.   0.25 0.   0.   0.   0.25 0.75]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [1.   0.   0.25 0.   0.75 0.5  0.   0.  ]\n",
            " [0.75 0.5  0.   0.25 0.75 0.   0.5  1.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SOREC(train_R = scaled_train_rating_matrix_toy, test_R = scaled_train_rating_matrix_toy, lambdaUVZ =0.008, learning_rate = 0.0008, trust = trust_toy, l=5, epochs = 1600)\n",
        "\n",
        "model.fit()\n",
        "print(model.get_complete_matrix())\n",
        "print(model.get_complete_matrix() * 4 + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbXMH1O4SIzT",
        "outputId": "ffdc32b3-44b9-40f6-bed9-04b2fb825296"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1600], total_loss: 1.4709248542785645, train_mae: 1.6546155214309692, test_mae: 1.6546155214309692\n",
            "Epoch [200/1600], total_loss: 0.663530707359314, train_mae: 0.5920348167419434, test_mae: 0.5920348167419434\n",
            "Epoch [400/1600], total_loss: 0.4109501838684082, train_mae: 0.4873964786529541, test_mae: 0.4873964786529541\n",
            "Epoch [600/1600], total_loss: 0.30223092436790466, train_mae: 0.4258694350719452, test_mae: 0.4258694350719452\n",
            "Epoch [800/1600], total_loss: 0.2516009211540222, train_mae: 0.39370301365852356, test_mae: 0.39370301365852356\n",
            "Epoch [1000/1600], total_loss: 0.23159053921699524, train_mae: 0.393073707818985, test_mae: 0.393073707818985\n",
            "Epoch [1200/1600], total_loss: 0.22501319646835327, train_mae: 0.40630602836608887, test_mae: 0.40630602836608887\n",
            "Epoch [1400/1600], total_loss: 0.22321143746376038, train_mae: 0.4151463210582733, test_mae: 0.4151463210582733\n",
            "tensor([[ 0.9319, -0.2698, -0.4257, -0.1775,  0.4683,  0.2253, -0.2035,  0.5309],\n",
            "        [ 1.1825, -0.0899, -0.6587, -0.5076,  1.3219,  0.1238, -0.2371,  1.1182],\n",
            "        [ 0.9876, -0.2101, -0.5882, -0.3232,  0.6588,  0.2068, -0.3810,  0.8378],\n",
            "        [ 1.0610, -0.3172, -0.6199, -0.2292,  0.4291,  0.2714, -0.4625,  0.7186],\n",
            "        [ 1.2983, -0.2901, -0.6285, -0.3329,  0.8933,  0.2518, -0.2652,  0.8670],\n",
            "        [ 0.8449, -0.1314, -0.4740, -0.3105,  0.7306,  0.1399, -0.2353,  0.7409]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "tensor([[ 4.7275, -0.0793, -0.7028,  0.2901,  2.8730,  1.9012,  0.1861,  3.1234],\n",
            "        [ 5.7301,  0.6402, -1.6350, -1.0304,  6.2876,  1.4954,  0.0516,  5.4728],\n",
            "        [ 4.9503,  0.1597, -1.3526, -0.2928,  3.6354,  1.8273, -0.5242,  4.3511],\n",
            "        [ 5.2442, -0.2687, -1.4796,  0.0831,  2.7164,  2.0856, -0.8501,  3.8742],\n",
            "        [ 6.1930, -0.1604, -1.5142, -0.3318,  4.5732,  2.0072, -0.0606,  4.4682],\n",
            "        [ 4.3795,  0.4742, -0.8959, -0.2419,  3.9223,  1.5596,  0.0589,  3.9636]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SOREC(train_R = scaled_train_rating_matrix_toy, test_R = scaled_train_rating_matrix_toy, lambdaUVZ =0.01, learning_rate = 0.001, trust = trust_toy, l=5, epochs = 1600)\n",
        "\n",
        "model.fit()\n",
        "print(model.get_complete_matrix())\n",
        "print(model.get_complete_matrix() * 4 + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5jJLbMBdOWy",
        "outputId": "66f8e48d-c736-4a9f-8cbf-9227da295d2a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1600], total_loss: 0.9359459280967712, train_mae: 1.4268125295639038, test_mae: 1.4268125295639038\n",
            "Epoch [200/1600], total_loss: 0.39830151200294495, train_mae: 0.6179636716842651, test_mae: 0.6179636716842651\n",
            "Epoch [400/1600], total_loss: 0.3318262994289398, train_mae: 0.4791382849216461, test_mae: 0.4791382849216461\n",
            "Epoch [600/1600], total_loss: 0.3090065121650696, train_mae: 0.44620513916015625, test_mae: 0.44620513916015625\n",
            "Epoch [800/1600], total_loss: 0.29405641555786133, train_mae: 0.4141961932182312, test_mae: 0.4141961932182312\n",
            "Epoch [1000/1600], total_loss: 0.28136950731277466, train_mae: 0.3903547525405884, test_mae: 0.3903547525405884\n",
            "Epoch [1200/1600], total_loss: 0.272945761680603, train_mae: 0.39312639832496643, test_mae: 0.39312639832496643\n",
            "Epoch [1400/1600], total_loss: 0.26824450492858887, train_mae: 0.39502519369125366, test_mae: 0.39502519369125366\n",
            "tensor([[ 0.7549, -0.1609, -0.3412, -0.1830,  0.4515,  0.1556, -0.1354,  0.5012],\n",
            "        [ 1.1045, -0.1071, -0.4572, -0.3032,  1.1772,  0.1438, -0.0427,  0.6781],\n",
            "        [ 0.7997, -0.1694, -0.4994, -0.2020,  0.3431,  0.1578, -0.3580,  0.6524],\n",
            "        [ 0.4574, -0.0361, -0.4390, -0.1261,  0.2692,  0.0375, -0.3950,  0.4630],\n",
            "        [ 1.1769, -0.2085, -0.5264, -0.2920,  0.8669,  0.2129, -0.1705,  0.7581],\n",
            "        [ 0.8075, -0.1499, -0.3770, -0.2125,  0.5514,  0.1539, -0.1518,  0.5650]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "tensor([[ 4.0196,  0.3566, -0.3649,  0.2679,  2.8059,  1.6224,  0.4586,  3.0049],\n",
            "        [ 5.4179,  0.5715, -0.8287, -0.2128,  5.7087,  1.5750,  0.8290,  3.7126],\n",
            "        [ 4.1990,  0.3226, -0.9976,  0.1922,  2.3725,  1.6313, -0.4318,  3.6095],\n",
            "        [ 2.8294,  0.8557, -0.7561,  0.4956,  2.0770,  1.1501, -0.5801,  2.8522],\n",
            "        [ 5.7077,  0.1661, -1.1055, -0.1680,  4.4675,  1.8515,  0.3179,  4.0326],\n",
            "        [ 4.2301,  0.4005, -0.5081,  0.1499,  3.2057,  1.6155,  0.3929,  3.2599]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 필요한 함수들\n",
        "def g(x):\n",
        "  return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "def g_prime(x):\n",
        "  return g(x) * (1- g(x))\n",
        "\n",
        "class SOREC(nn.Module):\n",
        "  def __init__(self, train_R = scaled_train_rating_matrix, test_R = scaled_test_rating_matrix, trust = ui_uk_matrix, l=10, lambC = 10, lambdaUVZ =0.01, learning_rate=1e-3, epochs= 100):\n",
        "    '''\n",
        "    SOREC\n",
        "    논문에서는 gradient descent 직접 업데이트하는 방식\n",
        "    구현은 pytorch의 loss.backward()\n",
        "    '''\n",
        "    super(SOREC, self).__init__()\n",
        "\n",
        "    # 논문은 특이하게 m이 user 수, n이 item 수\n",
        "    self.m, self.n = train_R.shape # Rating\n",
        "    self.test_n, self.test_m = test_R.shape\n",
        "\n",
        "    self.latent_dimension = l\n",
        "\n",
        "    self.train_R = train_R # 80            (100, 1000)\n",
        "    self.test_R = test_R   # 20 비율       (100, 1000)\n",
        "    self.trust = trust     # trust ratings (100, 100)\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.epoch = epochs\n",
        "    self.lambdaC = lambC\n",
        "    self.lambdaUVZ = lambdaUVZ # 공통으로 사용\n",
        "\n",
        "    self.U = nn.Parameter(torch.randn(self.latent_dimension, self.m)).to(device) # (l, m)\n",
        "    self.Z = nn.Parameter(torch.randn(self.latent_dimension, self.m)).to(device) # (l, m)\n",
        "    self.V = nn.Parameter(torch.randn(self.latent_dimension, self.n)).to(device) # (l, n)\n",
        "\n",
        "    # for SoReg\n",
        "    # self.outlink_friends = {user: np.where(self.trust[user, :] > 0)[0] for user in range(self.m)}\n",
        "    # self.inlink_friends = {user: np.where(self.trust[:, user] > 0)[0] for user in range(self.m)}\n",
        "\n",
        "    self.myparameters = nn.ParameterList([self.U, self.Z, self.V])\n",
        "\n",
        "    self.optimizer = torch.optim.Adam(self.myparameters, lr= self.lr)\n",
        "\n",
        "    self.completed_rating_matrix = torch.matmul(self.U.T, self.V)\n",
        "\n",
        "  def forward_user_item(self, u):\n",
        "    # user 들어올 때마다 모든 item에 대한 rating 차이 구하기\n",
        "    predicted_rating = g(torch.matmul(self.U[:, u].T, self.V)) # (l,) (l, n) => (n)\n",
        "    loss = 0\n",
        "    for v in range(1000):\n",
        "      # R이 있는 경우만\n",
        "      if self.train_R[u, v]:\n",
        "        loss += (self.train_R[u, v] - predicted_rating[v]) ** 2\n",
        "\n",
        "    return loss / 2\n",
        "\n",
        "  def forward_social(self, u):\n",
        "    # user 들어올 때마다 trusted user 대한 trust 차이 구하기\n",
        "    predicted_trust = g(torch.matmul(self.U[:, u].T, self.Z)) # (m)\n",
        "    loss = 0\n",
        "    for z in range(100):\n",
        "      if self.trust[u, z]:\n",
        "        loss += (self.trust[u, z] - predicted_trust[z]) ** 2\n",
        "\n",
        "    return self.lambdaC * loss / 2\n",
        "\n",
        "  def train_mae(self):\n",
        "    mae_loss = 0\n",
        "    train_num = 0\n",
        "    cm = torch.matmul(self.U.T, self.V)\n",
        "    for u in range(100):\n",
        "      for v in range(1000):\n",
        "        if self.train_R[u, v]:\n",
        "          train_num += 1 # .8\n",
        "          mae_loss += abs(cm[u, v] - self.train_R[u, v])\n",
        "\n",
        "    return mae_loss.item() / train_num\n",
        "\n",
        "  def test_accuracy(self):\n",
        "    mae_loss = 0\n",
        "    test_num = 0\n",
        "    cm = torch.matmul(self.U.T, self.V)\n",
        "    for u in range(100):\n",
        "      for v in range(1000):\n",
        "        if self.test_R[u, v]:\n",
        "          test_num += 1 # .2\n",
        "          mae_loss += abs(cm[u, v] - self.test_R[u, v])\n",
        "\n",
        "    return mae_loss.item() / test_num\n",
        "\n",
        "\n",
        "  def get_complete_matrix(self):\n",
        "    self.completed_rating_matrix  = torch.matmul(self.U.T, self.V)\n",
        "    return self.completed_rating_matrix\n",
        "\n",
        "  def fit(self):\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "\n",
        "    for epoch in range(self.epoch):\n",
        "      #print(epoch)\n",
        "      total_loss = 0\n",
        "      for u in range(self.m):\n",
        "\n",
        "        # user-item matrix loss\n",
        "        loss1 = self.forward_user_item(u)\n",
        "\n",
        "        # trust matrix loss\n",
        "        loss2 = self.forward_social(u)\n",
        "\n",
        "        total_loss = loss1 + loss2 + self.lambdaUVZ * (torch.sum(self.U ** 2) + torch.sum(self.V ** 2) + torch.sum(self.Z ** 2)).to(device)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        #self.completed_rating_matrix = torch.matmul(self.U.T, self.V)\n",
        "      test_mae = self.test_accuracy()\n",
        "      train_loss_list.append(total_loss)\n",
        "      test_loss_list.append(test_mae)\n",
        "\n",
        "      if epoch % 40 == 0:\n",
        "        train_mae = self.train_mae()\n",
        "        print(f'Epoch [{epoch}/{self.epoch}], total_loss: {total_loss}, train_mae: {train_mae} test_mae: {test_mae}')\n",
        "\n",
        "\n",
        "    return train_loss_list, test_loss_list\n",
        "\n",
        "\n",
        "model = SOREC(epochs=200).to(device)\n",
        "\n",
        "# Train the model\n",
        "train_loss_list, test_loss_list = model.fit()\n",
        "plt.plot(test_loss_list, label='Test Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "w76bQTVYbg2a",
        "outputId": "fdcedf6f-77de-46e0-958b-de2cf8ef8e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch [0/200], total_loss: 476.83154296875, train_mae: 2.3476864207319514 test_mae: 2.3469850702049144\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-12294d80558f>\u001b[0m in \u001b[0;36m<cell line: 142>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-12294d80558f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# user-item matrix loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_user_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# trust matrix loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-12294d80558f>\u001b[0m in \u001b[0;36mforward_user_item\u001b[0;34m(self, u)\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0;31m# R이 있는 경우만\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_R\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_R\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredicted_rating\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# See https://github.com/pytorch/pytorch/issues/75462\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T0H1wcaxo150"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}